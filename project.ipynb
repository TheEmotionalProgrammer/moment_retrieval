{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdYzrLhxMTlW",
        "outputId": "e8b40fd3-7aaf-404e-cb57-e43833d5fa75"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UmQotmJMUrs",
        "outputId": "349ac3e8-f333-47b7-c0d7-7ea7b937eb94"
      },
      "outputs": [],
      "source": [
        "# pip install python-terrier==0.10.0 nltk scikit-learn lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYhewvEjL-7Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import pyterrier as pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W17JgCyFL-7Z"
      },
      "outputs": [],
      "source": [
        "# Paths to JSONL files\n",
        "jsonl_train_path = './text_data/tvr_train_release.jsonl'\n",
        "jsonl_val_path = './text_data/tvr_val_release.jsonl'\n",
        "subs_path = './text_data/tvqa_preprocessed_subtitles.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UruQwRMsOrNj"
      },
      "outputs": [],
      "source": [
        "# Paths to JSONL files on Colab\n",
        "# jsonl_train_path = '/content/drive/MyDrive/IR/text_data/tvr_train_release.jsonl'\n",
        "# jsonl_val_path = '/content/drive/MyDrive/IR/text_data/tvr_val_release.jsonl'\n",
        "# subs_path = '/content/drive/MyDrive/IR/text_data/tvqa_preprocessed_subtitles.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6VZMDuDL-7Z"
      },
      "outputs": [],
      "source": [
        "# Load subtitles into a dictionary for quick access\n",
        "subtitles_dict = {}\n",
        "with open(subs_path, 'r') as subs_file:\n",
        "    for line in subs_file:\n",
        "        sub_data = json.loads(line)\n",
        "        subtitles_dict[sub_data['vid_name']] = sub_data['sub']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkWQOjjYL-7Z"
      },
      "outputs": [],
      "source": [
        "# Function to find matching subtitles\n",
        "def find_matching_subtitles(vid_name, ts_range, subtitles_dict):\n",
        "    matching_subs = []\n",
        "    if vid_name in subtitles_dict:\n",
        "        for subtitle in subtitles_dict[vid_name]:\n",
        "            if (ts_range[0] <= subtitle['start'] <= ts_range[1]) or (ts_range[0] <= subtitle['end'] <= ts_range[1]):\n",
        "                matching_subs.append(subtitle['text'])\n",
        "    return matching_subs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDx8ntjxL-7a"
      },
      "outputs": [],
      "source": [
        "def parse_jsonl(jsonl_path):\n",
        "    # Initialize empty lists for your data\n",
        "    queries_data = []\n",
        "    documents_data = []\n",
        "    query_rankings_data = []\n",
        "\n",
        "    with open(jsonl_path, 'r') as file:\n",
        "        for idx, line in enumerate(file):\n",
        "            data = json.loads(line)\n",
        "            # drop non text-based queries\n",
        "            if data['type'] not in ['t']:\n",
        "                continue\n",
        "\n",
        "            # Extract data for the Query Set DataFrame\n",
        "            queries_data.append({'qid': data['desc_id'], 'query': data['desc']})\n",
        "\n",
        "            # Find matching subtitles\n",
        "            matching_subs = find_matching_subtitles(data['vid_name'], data['ts'], subtitles_dict)\n",
        "\n",
        "            # Extract data for the Documents Set DataFrame, including matching subtitles\n",
        "            documents_data.append({'docno': idx, 'vid_name': data['vid_name'], 'ts': data['ts'],\n",
        "                                'duration': data['duration'], 'type': data['type'], 'subtitles': matching_subs})\n",
        "\n",
        "            # Extract data for the Query Rankings DataFrame\n",
        "            query_rankings_data.append({'qid': data[\"desc_id\"], 'query': data['desc'], 'docno': idx, 'rank': 1, 'score': 1.0})\n",
        "\n",
        "    return queries_data, documents_data, query_rankings_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OU_Us_DWL-7a"
      },
      "outputs": [],
      "source": [
        "train_queries_data, train_documents_data, train_query_rankings_data = parse_jsonl(jsonl_train_path)\n",
        "\n",
        "# Convert lists to DataFrames (training)\n",
        "train_query_set_df = pd.DataFrame(train_queries_data).set_index('qid')\n",
        "train_documents_set_df = pd.DataFrame(train_documents_data).set_index('docno')\n",
        "train_query_rankings_df = pd.DataFrame(train_query_rankings_data)\n",
        "\n",
        "val_queries_data, val_documents_data, val_query_rankings_data = parse_jsonl(jsonl_val_path)\n",
        "\n",
        "# Convert lists to DataFrames (validation)\n",
        "val_query_set_df = pd.DataFrame(val_queries_data).set_index('qid')\n",
        "val_documents_set_df = pd.DataFrame(val_documents_data).set_index('docno')\n",
        "val_query_rankings_df = pd.DataFrame(val_query_rankings_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTiDgmaqL-7a",
        "outputId": "455e4837-70fa-4c3f-af33-121958c54775"
      },
      "outputs": [],
      "source": [
        "#print the head of the dataframes\n",
        "print(train_query_set_df.head())\n",
        "print(train_documents_set_df.head())\n",
        "print(train_query_rankings_df.head())\n",
        "\n",
        "print(\"===================\")\n",
        "\n",
        "print(val_query_set_df.head())\n",
        "print(val_documents_set_df.head())\n",
        "print(val_query_rankings_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCaV5vcXL-7a"
      },
      "source": [
        "### First Stage Retrieval [TODO: BOX]\n",
        "The following part of the code will define three different first stage retrieval pipelines as an input for the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-SsgPJwVMXw",
        "outputId": "060130fa-47d3-454a-f99d-aa4cafb08e60"
      },
      "outputs": [],
      "source": [
        "if not pt.started():\n",
        "    pt.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ATVHECDfY6U"
      },
      "outputs": [],
      "source": [
        "# prepare the training data\n",
        "if 'docno' not in train_documents_set_df.columns:\n",
        "    train_documents_set_df.reset_index(inplace=True)\n",
        "\n",
        "train_documents_set_df['text'] = train_documents_set_df['subtitles'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "train_documents_set_df['docno'] = train_documents_set_df['docno'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prepare the training data\n",
        "if 'docno' not in val_documents_set_df.columns:\n",
        "    val_documents_set_df.reset_index(inplace=True)\n",
        "\n",
        "val_documents_set_df['text'] = val_documents_set_df['subtitles'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "val_documents_set_df['docno'] = val_documents_set_df['docno'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# join training with val for indexing\n",
        "joined_documents_set_df = pd.concat([train_documents_set_df, val_documents_set_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx55BjIGfNNa",
        "outputId": "12a0cc0f-2cba-4520-f160-4c6b51f77977"
      },
      "outputs": [],
      "source": [
        "# Create an index\n",
        "indexer = pt.DFIndexer(\"./index_path\", overwrite=True, meta=['docno'])\n",
        "indexed = indexer.index(joined_documents_set_df['text'], joined_documents_set_df['docno'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xuAPswuVQMe"
      },
      "outputs": [],
      "source": [
        "# Initialize BatchRetrieve with the created index and specify BM25 as the weighting model\n",
        "first_stage_bm25 = pt.BatchRetrieve(\n",
        "    indexed,\n",
        "    wmodel=\"BM25\",\n",
        "    num_results=3,\n",
        "    metadata=[\"docno\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vCeCMoUvedO"
      },
      "source": [
        "Computing feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTBZtHYLy_fH"
      },
      "outputs": [],
      "source": [
        "# features, can use any of the features in the list\n",
        "pl2_retriever = pt.BatchRetrieve(indexed, wmodel=\"PL2\", metadata=[\"docno\"])\n",
        "dph_retriever = pt.BatchRetrieve(indexed, wmodel=\"DPH\", metadata=[\"docno\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYrqwBx1vVn_"
      },
      "outputs": [],
      "source": [
        "# build a pipeline with the features\n",
        "pipeline_with_features = ~first_stage_bm25 >> (\n",
        "    pl2_retriever ** dph_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZGjM0th6a2Y"
      },
      "outputs": [],
      "source": [
        "# output the results of dataset and query, help to overview the data\n",
        "\n",
        "# train_documents_set_df = train_documents_set_df.dropna(subset=['text'])\n",
        "# excel_filepath = 'documents.xlsx'\n",
        "\n",
        "# train_documents_set_df.to_excel(excel_filepath, index=False, engine='openpyxl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE1WrfC8zJjm"
      },
      "outputs": [],
      "source": [
        "# Prepare the queries for the pipeline, remove special characters and extra spaces\n",
        "prepared_queries = train_query_set_df.reset_index()\n",
        "prepared_queries['qid'] = prepared_queries['qid'].astype(str)\n",
        "prepared_queries['query'] = prepared_queries['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
        "prepared_queries['query'] = prepared_queries['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
        "\n",
        "prepared_queries['query'] = prepared_queries['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "prepared_rankings = train_query_rankings_df.reset_index()\n",
        "prepared_rankings['qid'] = prepared_rankings['qid'].astype(str)\n",
        "prepared_rankings['docno'] = prepared_rankings['docno'].astype(str)\n",
        "prepared_rankings['query'] = prepared_rankings['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
        "prepared_rankings['query'] = prepared_rankings['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
        "prepared_rankings['query'] = prepared_rankings['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "prepared_rankings['label'] = prepared_rankings['score']\n",
        "\n",
        "prepared_rankings['label'] = prepared_rankings['label'].astype(int)\n",
        "\n",
        "prepared_valqueries = val_query_set_df.reset_index()\n",
        "prepared_valqueries['qid'] = prepared_valqueries['qid'].astype(str)\n",
        "prepared_valqueries['query'] = prepared_valqueries['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
        "prepared_valqueries['query'] = prepared_valqueries['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
        "\n",
        "prepared_valqueries['query'] = prepared_valqueries['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "prepared_valrankings = val_query_rankings_df.reset_index()\n",
        "prepared_valrankings['qid'] = prepared_valrankings['qid'].astype(str)\n",
        "prepared_valrankings['docno'] = prepared_valrankings['docno'].astype(str)\n",
        "prepared_valrankings['query'] = prepared_valrankings['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
        "prepared_valrankings['query'] = prepared_valrankings['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
        "prepared_valrankings['query'] = prepared_valrankings['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "prepared_valrankings['label'] = prepared_valrankings['score']\n",
        "# make the label an int\n",
        "prepared_valrankings['label'] = prepared_valrankings['label'].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeKG_RmLXDIA"
      },
      "outputs": [],
      "source": [
        "# divided in batch\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# batch_size = 100\n",
        "# n_batches = (len(prepared_queries) + batch_size - 1) // batch_size\n",
        "\n",
        "# for batch_num in tqdm(range(n_batches), desc=\"Processing batches\"):\n",
        "#     start_idx = batch_num * batch_size\n",
        "#     end_idx = start_idx + batch_size\n",
        "#     batch_queries = prepared_queries[start_idx:end_idx]\n",
        "\n",
        "#     # run pipeline\n",
        "#     batch_results = pipeline_with_features(batch_queries)\n",
        "\n",
        "#     # write or append\n",
        "#     mode = 'w' if batch_num == 0 else 'a'\n",
        "#     header = True if batch_num == 0 else False\n",
        "\n",
        "#     # to csv\n",
        "#     batch_results.to_csv('results_with_features.csv', mode=mode, header=header, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "-vOyqSXLOlkl",
        "outputId": "1cd51f2c-d50b-404f-ff3f-6299385494bc"
      },
      "outputs": [],
      "source": [
        "# directly run the pipeline\n",
        "# results_with_features = pipeline_with_features(prepared_queries)\n",
        "# batch_results.to_csv('results_with_features.csv', mode='w', header=True, index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5tgRqDUL-7c"
      },
      "source": [
        "### Learning [TODO: ROB]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrdQOXQ3L-7c"
      },
      "source": [
        "#### Definition of learned rankers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTHY4nOeL-7c"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "index = pt.IndexFactory.of(\"./index_path\")\n",
        "\n",
        "# load results from csv\n",
        "# results_with_features = pd.read_csv('/content/drive/MyDrive/IR/results_with_features.csv')\n",
        "fsr_pipelines = [\n",
        "    pipeline_with_features\n",
        "]\n",
        "\n",
        "learned_models = [\n",
        "    SVR()\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAfI165IL-7c"
      },
      "source": [
        "#### Rankers training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiUuKHweL-7c"
      },
      "outputs": [],
      "source": [
        "trained_models = [first_stage_bm25]\n",
        "names = ['BM25']\n",
        "\n",
        "# ltr_svm = ~pipeline_with_features >> pt.ltr.apply_learned_model(SVR())\n",
        "\n",
        "# ltr_svm.fit(\n",
        "#     prepared_queries,\n",
        "#     train_query_rankings_df,\n",
        "#     # train_documents_set_df\n",
        "# )\n",
        "\n",
        "for fsr_pipeline in fsr_pipelines:\n",
        "    for model in learned_models:\n",
        "        names.append(f\"prova_{model.__class__.__name__}\")\n",
        "        pipe = fsr_pipeline >> pt.ltr.apply_learned_model(model)\n",
        "        pipe.fit(\n",
        "            prepared_queries,\n",
        "            prepared_rankings\n",
        "        )\n",
        "        trained_models.append(pipe)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP5_lc-2L-7c"
      },
      "source": [
        "#### Rankers evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "3-fTOmcjL-7c",
        "outputId": "ddb49c07-4e68-4c8b-dc98-98af8981f1b2"
      },
      "outputs": [],
      "source": [
        "from pyterrier.measures import nDCG, RR, MAP\n",
        "\n",
        "pt.Experiment(\n",
        "    trained_models,\n",
        "    prepared_valqueries,\n",
        "    prepared_valrankings,\n",
        "    names=['BM25', 'BM25 > SVR'],\n",
        "    eval_metrics=[nDCG @ 3, RR @ 3, MAP],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "pt.Experiment(\n",
        "    trained_models,\n",
        "    prepared_queries,\n",
        "    prepared_rankings,\n",
        "    names=['BM25', 'BM25 > SVR'],\n",
        "    eval_metrics=[nDCG @ 3, RR @ 3, MAP],\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
