{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdYzrLhxMTlW",
        "outputId": "4a0a42f4-b270-49df-ad20-8f45b86b2731"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UmQotmJMUrs",
        "outputId": "58c35d61-7541-47a2-c5a7-b8b550a1d4a1"
      },
      "outputs": [],
      "source": [
        "pip install python-terrier==0.10.0 nltk scikit-learn lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYhewvEjL-7Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import pyterrier as pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W17JgCyFL-7Z"
      },
      "outputs": [],
      "source": [
        "# Paths to JSONL files\n",
        "jsonl_train_path = './text_data/tvr_train_release.jsonl'\n",
        "jsonl_val_path = './text_data/tvr_val_release.jsonl'\n",
        "subs_path = '.text_data/tvqa_preprocessed_subtitles.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UruQwRMsOrNj"
      },
      "outputs": [],
      "source": [
        "# Paths to JSONL files on Colab\n",
        "jsonl_train_path = '/content/drive/MyDrive/IR/text_data/tvr_train_release.jsonl'\n",
        "jsonl_val_path = '/content/drive/MyDrive/IR/text_data/tvr_val_release.jsonl'\n",
        "subs_path = '/content/drive/MyDrive/IR/text_data/tvqa_preprocessed_subtitles.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6VZMDuDL-7Z"
      },
      "outputs": [],
      "source": [
        "# Load subtitles into a dictionary for quick access\n",
        "subtitles_dict = {}\n",
        "with open(subs_path, 'r') as subs_file:\n",
        "    for line in subs_file:\n",
        "        sub_data = json.loads(line)\n",
        "        subtitles_dict[sub_data['vid_name']] = sub_data['sub']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkWQOjjYL-7Z"
      },
      "outputs": [],
      "source": [
        "# Function to find matching subtitles\n",
        "def find_matching_subtitles(vid_name, ts_range, subtitles_dict):\n",
        "    matching_subs = []\n",
        "    if vid_name in subtitles_dict:\n",
        "        for subtitle in subtitles_dict[vid_name]:\n",
        "            if (ts_range[0] <= subtitle['start'] <= ts_range[1]) or (ts_range[0] <= subtitle['end'] <= ts_range[1]):\n",
        "                matching_subs.append(subtitle['text'])\n",
        "    return matching_subs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDx8ntjxL-7a"
      },
      "outputs": [],
      "source": [
        "def parse_jsonl(jsonl_path):\n",
        "    # Initialize empty lists for your data\n",
        "    queries_data = []\n",
        "    documents_data = []\n",
        "    query_rankings_data = []\n",
        "\n",
        "    with open(jsonl_path, 'r') as file:\n",
        "        for idx, line in enumerate(file):\n",
        "            data = json.loads(line)\n",
        "\n",
        "            # Extract data for the Query Set DataFrame\n",
        "            queries_data.append({'qid': data['desc_id'], 'query': data['desc']})\n",
        "\n",
        "            # Find matching subtitles\n",
        "            matching_subs = find_matching_subtitles(data['vid_name'], data['ts'], subtitles_dict)\n",
        "\n",
        "            # Extract data for the Documents Set DataFrame, including matching subtitles\n",
        "            documents_data.append({'docno': idx, 'vid_name': data['vid_name'], 'ts': data['ts'],\n",
        "                                'duration': data['duration'], 'type': data['type'], 'subtitles': matching_subs})\n",
        "\n",
        "            # Extract data for the Query Rankings DataFrame\n",
        "            query_rankings_data.append({'qid': data[\"desc_id\"], 'query': data['desc'], 'docno': idx, 'rank': 1, 'score': 1.0})\n",
        "\n",
        "    return queries_data, documents_data, query_rankings_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OU_Us_DWL-7a"
      },
      "outputs": [],
      "source": [
        "train_queries_data, train_documents_data, train_query_rankings_data = parse_jsonl(jsonl_train_path)\n",
        "\n",
        "# Convert lists to DataFrames (training)\n",
        "train_query_set_df = pd.DataFrame(train_queries_data).set_index('qid')\n",
        "train_documents_set_df = pd.DataFrame(train_documents_data).set_index('docno')\n",
        "train_query_rankings_df = pd.DataFrame(train_query_rankings_data)\n",
        "\n",
        "val_queries_data, val_documents_data, val_query_rankings_data = parse_jsonl(jsonl_val_path)\n",
        "\n",
        "# Convert lists to DataFrames (validation)\n",
        "val_query_set_df = pd.DataFrame(val_queries_data).set_index('qid')\n",
        "val_documents_set_df = pd.DataFrame(val_documents_data).set_index('docno')\n",
        "val_query_rankings_df = pd.DataFrame(val_query_rankings_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTiDgmaqL-7a",
        "outputId": "53c9322a-6c20-4bfd-a3bb-65d81e0b9e6f"
      },
      "outputs": [],
      "source": [
        "#print the head of the dataframes\n",
        "print(train_query_set_df.head())\n",
        "print(train_documents_set_df.head())\n",
        "print(train_query_rankings_df.head())\n",
        "\n",
        "print(val_query_set_df.head())\n",
        "print(val_documents_set_df.head())\n",
        "print(val_query_rankings_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz9EktOSRwCb",
        "outputId": "ec3c9adf-b128-4817-9f93-98e56cd5749c"
      },
      "outputs": [],
      "source": [
        "print(train_query_set_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCaV5vcXL-7a"
      },
      "source": [
        "### First Stage Retrieval [TODO: BOX]\n",
        "The following part of the code will define three different first stage retrieval pipelines as an input for the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-SsgPJwVMXw"
      },
      "outputs": [],
      "source": [
        "if not pt.started():\n",
        "    pt.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ATVHECDfY6U"
      },
      "outputs": [],
      "source": [
        "if 'docno' not in train_documents_set_df.columns:\n",
        "    train_documents_set_df.reset_index(inplace=True)\n",
        "\n",
        "train_documents_set_df['text'] = train_documents_set_df['subtitles'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "train_documents_set_df['docno'] = train_documents_set_df['docno'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx55BjIGfNNa",
        "outputId": "ae06426b-094b-4f06-f833-92b3319c5b9e"
      },
      "outputs": [],
      "source": [
        "indexer = pt.DFIndexer(\"/content/index_path\", overwrite=True, meta=['docno'])\n",
        "indexed = indexer.index(train_documents_set_df['text'], train_documents_set_df['docno'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xuAPswuVQMe"
      },
      "outputs": [],
      "source": [
        "# Initialize BatchRetrieve with the created index and specify BM25 as the weighting model\n",
        "first_stage_bm25 = pt.BatchRetrieve(\n",
        "    indexed,\n",
        "    wmodel=\"BM25\",\n",
        "    num_results=100,\n",
        "    metadata=[\"docno\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vCeCMoUvedO"
      },
      "source": [
        "Computing feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTBZtHYLy_fH"
      },
      "outputs": [],
      "source": [
        "# Assuming `index` has been previously defined and points to the index created\n",
        "pl2_retriever = pt.BatchRetrieve(indexed, wmodel=\"PL2\", metadata=[\"docno\"])\n",
        "dph_retriever = pt.BatchRetrieve(indexed, wmodel=\"DPH\", metadata=[\"docno\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYrqwBx1vVn_"
      },
      "outputs": [],
      "source": [
        "pipeline_with_features = ~first_stage_bm25 >> (\n",
        "    pl2_retriever ** dph_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZGjM0th6a2Y"
      },
      "outputs": [],
      "source": [
        "train_documents_set_df = train_documents_set_df.dropna(subset=['text'])\n",
        "excel_filepath = 'documents.xlsx'\n",
        "\n",
        "train_documents_set_df.to_excel(excel_filepath, index=False, engine='openpyxl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE1WrfC8zJjm"
      },
      "outputs": [],
      "source": [
        "prepared_queries = train_query_set_df.reset_index()\n",
        "prepared_queries['qid'] = prepared_queries['qid'].astype(str)\n",
        "prepared_queries['query'] = prepared_queries['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
        "prepared_queries['query'] = prepared_queries['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
        "\n",
        "prepared_queries['query'] = prepared_queries['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "\n",
        "# Run the pipeline\n",
        "results_with_features = pipeline_with_features(prepared_queries)\n",
        "\n",
        "# Display the results\n",
        "print(results_with_features.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vOyqSXLOlkl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5tgRqDUL-7c"
      },
      "source": [
        "### Learning [TODO: ROB]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrdQOXQ3L-7c"
      },
      "source": [
        "#### Definition of learned rankers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTHY4nOeL-7c"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "learned_models = [\n",
        "    SVR()\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAfI165IL-7c"
      },
      "source": [
        "#### Rankers training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiUuKHweL-7c"
      },
      "outputs": [],
      "source": [
        "trained_models = []\n",
        "names = []\n",
        "\n",
        "for fsr_pipeline in fsr_pipelines:\n",
        "    for model in learned_models:\n",
        "        names.append(f\"{fsr_pipeline.name()}_{model.__class__.__name__}\")\n",
        "        pipe = ~fsr_pipeline >> pt.ltr.apply_learned_model(model)\n",
        "        pipe.fit(\n",
        "            train_query_rankings_df,\n",
        "            train_query_set_df,\n",
        "            train_documents_set_df\n",
        "        )\n",
        "        trained_models.append(pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP5_lc-2L-7c"
      },
      "source": [
        "#### Rankers evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-fTOmcjL-7c"
      },
      "outputs": [],
      "source": [
        "from pyterrier.measures import nDCG, RR, MAP\n",
        "\n",
        "pt.Experiment(\n",
        "    trained_models,\n",
        "    val_query_set_df,\n",
        "    val_query_rankings_df,\n",
        "    names=names,\n",
        "    eval_metrics=[nDCG @ 10, RR @ 10, MAP],\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
