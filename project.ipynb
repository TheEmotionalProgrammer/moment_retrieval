{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pyterrier as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to JSONL files\n",
    "jsonl_train_path = './text_data/tvr_train_release.jsonl'\n",
    "jsonl_val_path = './text_data/tvr_val_release.jsonl'\n",
    "subs_path = './text_data/tvqa_preprocessed_subtitles.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subtitles into a dictionary for quick access\n",
    "subtitles_dict = {}\n",
    "with open(subs_path, 'r') as subs_file:\n",
    "    for line in subs_file:\n",
    "        sub_data = json.loads(line)\n",
    "        subtitles_dict[sub_data['vid_name']] = sub_data['sub']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find matching subtitles\n",
    "def find_matching_subtitles(vid_name, ts_range, subtitles_dict):\n",
    "    matching_subs = []\n",
    "    if vid_name in subtitles_dict:\n",
    "        for subtitle in subtitles_dict[vid_name]:\n",
    "            if (ts_range[0] <= subtitle['start'] <= ts_range[1]) or (ts_range[0] <= subtitle['end'] <= ts_range[1]):\n",
    "                matching_subs.append(subtitle['text'])\n",
    "    return matching_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_jsonl(jsonl_path):\n",
    "    # Initialize empty lists for your data\n",
    "    queries_data = []\n",
    "    documents_data = []\n",
    "    query_rankings_data = []\n",
    "\n",
    "    with open(jsonl_path, 'r') as file:\n",
    "        for idx, line in enumerate(file):\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # Extract data for the Query Set DataFrame\n",
    "            queries_data.append({'qid': data['desc_id'], 'query': data['desc']})\n",
    "            \n",
    "            # Find matching subtitles\n",
    "            matching_subs = find_matching_subtitles(data['vid_name'], data['ts'], subtitles_dict)\n",
    "            \n",
    "            # Extract data for the Documents Set DataFrame, including matching subtitles\n",
    "            documents_data.append({'docno': idx, 'vid_name': data['vid_name'], 'ts': data['ts'], \n",
    "                                'duration': data['duration'], 'type': data['type'], 'subtitles': matching_subs})\n",
    "            \n",
    "            # Extract data for the Query Rankings DataFrame\n",
    "            query_rankings_data.append({'qid': data[\"desc_id\"], 'query': data['desc'], 'docno': idx, 'rank': 1, 'score': 1.0})\n",
    "\n",
    "    return queries_data, documents_data, query_rankings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries_data, train_documents_data, train_query_rankings_data = parse_jsonl(jsonl_train_path)\n",
    "\n",
    "# Convert lists to DataFrames (training)\n",
    "train_query_set_df = pd.DataFrame(train_queries_data).set_index('qid')\n",
    "train_documents_set_df = pd.DataFrame(train_documents_data).set_index('docno')\n",
    "train_query_rankings_df = pd.DataFrame(train_query_rankings_data)\n",
    "\n",
    "val_queries_data, val_documents_data, val_query_rankings_data = parse_jsonl(jsonl_val_path)\n",
    "\n",
    "# Convert lists to DataFrames (validation)\n",
    "val_query_set_df = pd.DataFrame(val_queries_data).set_index('qid')\n",
    "val_documents_set_df = pd.DataFrame(val_documents_data).set_index('docno')\n",
    "val_query_rankings_df = pd.DataFrame(val_query_rankings_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the head of the dataframes\n",
    "print(train_query_set_df.head())\n",
    "print(train_documents_set_df.head())\n",
    "print(train_query_rankings_df.head())\n",
    "\n",
    "print(val_query_set_df.head())\n",
    "print(val_documents_set_df.head())\n",
    "print(val_query_rankings_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Stage Retrieval [TODO: BOX]\n",
    "The following part of the code will define three different first stage retrieval pipelines as an input for the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsr_pipelines = [] ### I expect this to be the list of the first stage retrieval pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning [TODO: ROB]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of learned rankers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "learned_models = [\n",
    "    SVR()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rankers training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = []\n",
    "names = []\n",
    "\n",
    "for fsr_pipeline in fsr_pipelines:\n",
    "    for model in learned_models:\n",
    "        names.append(f\"{fsr_pipeline.name()}_{model.__class__.__name__}\")\n",
    "        pipe = ~fsr_pipeline >> pt.ltr.apply_learned_model(model)\n",
    "        pipe.fit(\n",
    "            train_query_rankings_df,\n",
    "            train_query_set_df,\n",
    "            train_documents_set_df\n",
    "        )\n",
    "        trained_models.append(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rankers evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.measures import nDCG, RR, MAP\n",
    "\n",
    "pt.Experiment(\n",
    "    trained_models,\n",
    "    val_query_set_df,\n",
    "    val_query_rankings_df,\n",
    "    names=names,\n",
    "    eval_metrics=[nDCG @ 10, RR @ 10, MAP],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
