{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdYzrLhxMTlW",
        "outputId": "5f4ca82b-a656-4f6a-b3c7-c3b89c2005cf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UmQotmJMUrs",
        "outputId": "ca5cf1b2-838f-4836-e3d6-56c4bfc3a32a"
      },
      "outputs": [],
      "source": [
        "pip install python-terrier==0.10.0 nltk scikit-learn lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EYhewvEjL-7Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import pyterrier as pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W17JgCyFL-7Z"
      },
      "outputs": [],
      "source": [
        "# Paths to JSONL files\n",
        "jsonl_train_path = 'text_data/tvr_train_release.jsonl'\n",
        "jsonl_val_path = 'text_data/tvr_val_release.jsonl'\n",
        "subs_path = 'text_data/tvqa_preprocessed_subtitles.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UruQwRMsOrNj"
      },
      "outputs": [],
      "source": [
        "# Paths to JSONL files on Colab\n",
        "jsonl_train_path = '/content/drive/MyDrive/IR/text_data/tvr_train_release.jsonl'\n",
        "jsonl_val_path = '/content/drive/MyDrive/IR/text_data/tvr_val_release.jsonl'\n",
        "subs_path = '/content/drive/MyDrive/IR/text_data/tvqa_preprocessed_subtitles.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L6VZMDuDL-7Z"
      },
      "outputs": [],
      "source": [
        "# Load subtitles into a dictionary for quick access\n",
        "subtitles_dict = {}\n",
        "with open(subs_path, 'r') as subs_file:\n",
        "    for line in subs_file:\n",
        "        sub_data = json.loads(line)\n",
        "        subtitles_dict[sub_data['vid_name']] = sub_data['sub']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UkWQOjjYL-7Z"
      },
      "outputs": [],
      "source": [
        "# Function to find matching subtitles\n",
        "def find_matching_subtitles(vid_name, ts_range, subtitles_dict):\n",
        "    matching_subs = []\n",
        "    if vid_name in subtitles_dict:\n",
        "        for subtitle in subtitles_dict[vid_name]:\n",
        "            if (ts_range[0] <= subtitle['start'] <= ts_range[1]) or (ts_range[0] <= subtitle['end'] <= ts_range[1]) or (subtitle['start'] <= ts_range[0] and subtitle['end'] >= ts_range[1]):\n",
        "                matching_subs.append(subtitle['text'])\n",
        "    return matching_subs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HDx8ntjxL-7a"
      },
      "outputs": [],
      "source": [
        "def parse_jsonl(jsonl_path):\n",
        "    # Initialize empty lists for your data\n",
        "    queries_data = []\n",
        "    documents_data = []\n",
        "    query_rankings_data = []\n",
        "\n",
        "    with open(jsonl_path, 'r') as file:\n",
        "        for idx, line in enumerate(file):\n",
        "            data = json.loads(line)\n",
        "            # drop non text-based queries\n",
        "            if data['type'] != 't':\n",
        "                continue\n",
        "\n",
        "            # Find matching subtitles\n",
        "            matching_subs = find_matching_subtitles(data['vid_name'], data['ts'], subtitles_dict)\n",
        "            if matching_subs == []:\n",
        "                continue\n",
        "\n",
        "            # Extract data for the Query Set DataFrame\n",
        "            queries_data.append({'qid': data['desc_id'], 'query': data['desc']})\n",
        "\n",
        "            # Extract data for the Documents Set DataFrame, including matching subtitles\n",
        "            documents_data.append({'docno': idx, 'vid_name': data['vid_name'], 'ts': data['ts'],\n",
        "                                'duration': data['duration'], 'type': data['type'], 'text': \"\".join(matching_subs)})\n",
        "\n",
        "            # Extract data for the Query Rankings DataFrame\n",
        "            query_rankings_data.append({'qid': data[\"desc_id\"], 'query': data['desc'], 'docno': idx, 'rank': 1, 'score': 1.0})\n",
        "\n",
        "    return queries_data, documents_data, query_rankings_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OU_Us_DWL-7a"
      },
      "outputs": [],
      "source": [
        "train_queries_data, train_documents_data, train_query_rankings_data = parse_jsonl(jsonl_train_path)\n",
        "\n",
        "# Convert lists to DataFrames (training)\n",
        "train_query_set_df = pd.DataFrame(train_queries_data)\n",
        "train_documents_set_df = pd.DataFrame(train_documents_data)\n",
        "train_query_rankings_df = pd.DataFrame(train_query_rankings_data)\n",
        "\n",
        "val_queries_data, val_documents_data, val_query_rankings_data = parse_jsonl(jsonl_val_path)\n",
        "\n",
        "# Convert lists to DataFrames (validation)\n",
        "val_query_set_df = pd.DataFrame(val_queries_data)\n",
        "val_documents_set_df = pd.DataFrame(val_documents_data)\n",
        "val_query_rankings_df = pd.DataFrame(val_query_rankings_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTiDgmaqL-7a",
        "outputId": "c03ef073-8d04-4d9c-d9b8-985c049873b1"
      },
      "outputs": [],
      "source": [
        "#print the length of the dataframes\n",
        "print(len(train_query_set_df))\n",
        "print(len(train_documents_set_df))\n",
        "print(len(train_query_rankings_df))\n",
        "\n",
        "print(len(val_query_set_df))\n",
        "print(len(val_documents_set_df))\n",
        "print(len(val_query_rankings_df))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCaV5vcXL-7a"
      },
      "source": [
        "### First Stage Retrieval [TODO: BOX]\n",
        "The following part of the code will define three different first stage retrieval pipelines as an input for the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-SsgPJwVMXw",
        "outputId": "3ed99e79-9cff-4669-97ad-4bc4d22ffc55"
      },
      "outputs": [],
      "source": [
        "if not pt.started():\n",
        "    pt.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6ATVHECDfY6U"
      },
      "outputs": [],
      "source": [
        "train_documents_set_df['docno'] = train_documents_set_df['docno'].astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx55BjIGfNNa",
        "outputId": "eeaddf3b-c0e7-4856-bce4-5ec6d5e1ec9d"
      },
      "outputs": [],
      "source": [
        "# Create an index\n",
        "from pathlib import Path\n",
        "\n",
        "indexer = pt.IterDictIndexer(\n",
        "    \"./index_path/\",\n",
        "    meta={\n",
        "        \"docno\": 16,\n",
        "        \"vid_name\": 64,\n",
        "        \"text\": 131072,\n",
        "    },\n",
        "    stemmer=\"porter\",\n",
        "    stopwords=\"terrier\",\n",
        "    overwrite=True,\n",
        "    type=pt.index.IndexingType.MEMORY,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "indexed = indexer.index(train_documents_set_df.to_dict('records'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9xuAPswuVQMe"
      },
      "outputs": [],
      "source": [
        "# Initialize BatchRetrieve with the created index and specify BM25 as the weighting model\n",
        "first_stage_bm25 = pt.BatchRetrieve(\n",
        "    indexed,\n",
        "    wmodel=\"BM25\",\n",
        "    num_results=10,\n",
        "    metadata=[\"docno\", \"vid_name\", \"text\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vCeCMoUvedO"
      },
      "source": [
        "Computing feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QTBZtHYLy_fH"
      },
      "outputs": [],
      "source": [
        "# features, can use any of the features in the list\n",
        "\n",
        "pl2_retriever = pt.BatchRetrieve(indexed, wmodel=\"PL2\")\n",
        "dph_retriever = pt.BatchRetrieve(indexed, wmodel=\"DPH\")\n",
        "#tf_idf_retriever = pt.BatchRetrieve(indexed, wmodel=\"TF_IDF\")\n",
        "#bb2_retriever = pt.BatchRetrieve(indexed, wmodel=\"BB2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AYrqwBx1vVn_"
      },
      "outputs": [],
      "source": [
        "# build a pipeline with the features\n",
        "pipeline_with_features = ~first_stage_bm25 >> (\n",
        "    pl2_retriever ** dph_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QE1WrfC8zJjm"
      },
      "outputs": [],
      "source": [
        "# Prepare the queries for the pipeline, remove special characters and extra spaces\n",
        "prepared_queries = train_query_set_df\n",
        "prepared_queries['qid'] = prepared_queries['qid'].astype(str)\n",
        "prepared_queries['query'] = prepared_queries['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
        "prepared_queries['query'] = prepared_queries['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
        "prepared_queries['query'] = prepared_queries['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "BeKG_RmLXDIA",
        "outputId": "233a8d12-54a8-47a2-febd-54d5dba9ac8c"
      },
      "outputs": [],
      "source": [
        "# # divided in batch\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# batch_size = 100\n",
        "# n_batches = (len(prepared_queries) + batch_size - 1) // batch_size\n",
        "\n",
        "# for batch_num in tqdm(range(n_batches), desc=\"Processing batches\"):\n",
        "#     start_idx = batch_num * batch_size\n",
        "#     end_idx = start_idx + batch_size\n",
        "#     batch_queries = prepared_queries[start_idx:end_idx]\n",
        "\n",
        "#     # run pipeline\n",
        "#     batch_results = pipeline_with_features(batch_queries)\n",
        "\n",
        "#     # write or append\n",
        "#     mode = 'w' if batch_num == 0 else 'a'\n",
        "#     header = True if batch_num == 0 else False\n",
        "\n",
        "#     # to csv\n",
        "#     batch_results.to_csv('results_with_features.csv', mode=mode, header=header, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vOyqSXLOlkl"
      },
      "outputs": [],
      "source": [
        "#batch_results.to_csv('results_with_features.csv', mode='w', header=True, index=False)\n",
        "\n",
        "results_with_features = pipeline_with_features(prepared_queries)\n",
        "print(results_with_features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5tgRqDUL-7c"
      },
      "source": [
        "### Learning [TODO: ROB]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrdQOXQ3L-7c"
      },
      "source": [
        "#### Definition of learned rankers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTHY4nOeL-7c"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "learned_models = [\n",
        "    SVR()\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAfI165IL-7c"
      },
      "source": [
        "#### Rankers training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiUuKHweL-7c"
      },
      "outputs": [],
      "source": [
        "trained_models = []\n",
        "names = []\n",
        "\n",
        "for fsr_pipeline in fsr_pipelines:\n",
        "    for model in learned_models:\n",
        "        names.append(f\"{fsr_pipeline.name()}_{model.__class__.__name__}\")\n",
        "        pipe = ~fsr_pipeline >> pt.ltr.apply_learned_model(model)\n",
        "        pipe.fit(\n",
        "            train_query_rankings_df,\n",
        "            train_query_set_df,\n",
        "            train_documents_set_df\n",
        "        )\n",
        "        trained_models.append(pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP5_lc-2L-7c"
      },
      "source": [
        "#### Rankers evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-fTOmcjL-7c"
      },
      "outputs": [],
      "source": [
        "from pyterrier.measures import nDCG, RR, MAP\n",
        "\n",
        "pt.Experiment(\n",
        "    trained_models,\n",
        "    val_query_set_df,\n",
        "    val_query_rankings_df,\n",
        "    names=names,\n",
        "    eval_metrics=[nDCG @ 10, RR @ 10, MAP],\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
