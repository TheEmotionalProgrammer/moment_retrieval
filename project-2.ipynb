{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7977303,"sourceType":"datasetVersion","datasetId":4694824}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EdYzrLhxMTlW","outputId":"34f98e14-b479-4070-90ac-139dc7a222b2","execution":{"iopub.status.busy":"2024-03-30T12:24:31.535078Z","iopub.execute_input":"2024-03-30T12:24:31.535496Z","iopub.status.idle":"2024-03-30T12:24:31.540696Z","shell.execute_reply.started":"2024-03-30T12:24:31.535465Z","shell.execute_reply":"2024-03-30T12:24:31.539530Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install python-terrier==0.10.0 nltk scikit-learn lightgbm xgboost fastrank","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3UmQotmJMUrs","outputId":"b33cf819-d36d-4aad-a73a-d3ae37d66151","execution":{"iopub.status.busy":"2024-03-30T12:24:31.577199Z","iopub.execute_input":"2024-03-30T12:24:31.577974Z","iopub.status.idle":"2024-03-30T12:25:39.216599Z","shell.execute_reply.started":"2024-03-30T12:24:31.577932Z","shell.execute_reply":"2024-03-30T12:25:39.214787Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting python-terrier==0.10.0\n  Downloading python-terrier-0.10.0.tar.gz (107 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (4.2.0)\nRequirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (2.0.3)\nCollecting fastrank\n  Downloading fastrank-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from python-terrier==0.10.0) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from python-terrier==0.10.0) (2.2.0)\nCollecting wget (from python-terrier==0.10.0)\n  Downloading wget-3.2.zip (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from python-terrier==0.10.0) (4.66.1)\nCollecting pyjnius>=1.4.2 (from python-terrier==0.10.0)\n  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nCollecting matchpy (from python-terrier==0.10.0)\n  Downloading matchpy-0.5.5-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: deprecated in /opt/conda/lib/python3.10/site-packages (from python-terrier==0.10.0) (1.2.14)\nCollecting chest (from python-terrier==0.10.0)\n  Downloading chest-0.2.3.tar.gz (9.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from python-terrier==0.10.0) (1.11.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from python-terrier==0.10.0) (2.31.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from python-terrier==0.10.0) (1.3.2)\nCollecting nptyping==1.4.4 (from python-terrier==0.10.0)\n  Downloading nptyping-1.4.4-py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: more_itertools in /opt/conda/lib/python3.10/site-packages (from python-terrier==0.10.0) (10.2.0)\nCollecting ir_datasets>=0.3.2 (from python-terrier==0.10.0)\n  Downloading ir_datasets-0.5.6-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from python-terrier==0.10.0) (3.1.2)\nRequirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (from python-terrier==0.10.0) (0.14.1)\nCollecting ir_measures>=0.3.1 (from python-terrier==0.10.0)\n  Downloading ir_measures-0.3.3.tar.gz (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from python-terrier==0.10.0) (0.3.8)\nCollecting pytrec_eval_terrier>=0.5.3 (from python-terrier==0.10.0)\n  Downloading pytrec_eval_terrier-0.5.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (777 bytes)\nCollecting typish>=1.7.0 (from nptyping==1.4.4->python-terrier==0.10.0)\n  Downloading typish-1.9.3-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fastrank) (1.16.0)\nRequirement already satisfied: beautifulsoup4>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from ir_datasets>=0.3.2->python-terrier==0.10.0) (4.12.2)\nCollecting inscriptis>=2.2.0 (from ir_datasets>=0.3.2->python-terrier==0.10.0)\n  Downloading inscriptis-2.5.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: lxml>=4.5.2 in /opt/conda/lib/python3.10/site-packages (from ir_datasets>=0.3.2->python-terrier==0.10.0) (5.1.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ir_datasets>=0.3.2->python-terrier==0.10.0) (6.0.1)\nCollecting trec-car-tools>=2.5.4 (from ir_datasets>=0.3.2->python-terrier==0.10.0)\n  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\nRequirement already satisfied: lz4>=3.1.10 in /opt/conda/lib/python3.10/site-packages (from ir_datasets>=0.3.2->python-terrier==0.10.0) (4.3.3)\nCollecting warc3-wet>=0.2.3 (from ir_datasets>=0.3.2->python-terrier==0.10.0)\n  Downloading warc3_wet-0.2.3-py3-none-any.whl.metadata (2.0 kB)\nCollecting warc3-wet-clueweb09>=0.2.5 (from ir_datasets>=0.3.2->python-terrier==0.10.0)\n  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting zlib-state>=0.1.3 (from ir_datasets>=0.3.2->python-terrier==0.10.0)\n  Downloading zlib-state-0.1.6.tar.gz (9.5 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting ijson>=3.1.3 (from ir_datasets>=0.3.2->python-terrier==0.10.0)\n  Downloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nCollecting pyautocorpus>=0.1.1 (from ir_datasets>=0.3.2->python-terrier==0.10.0)\n  Downloading pyautocorpus-0.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting unlzw3>=0.2.1 (from ir_datasets>=0.3.2->python-terrier==0.10.0)\n  Downloading unlzw3-0.2.2-py3-none-any.whl.metadata (2.4 kB)\nCollecting cwl-eval>=1.0.10 (from ir_measures>=0.3.1->python-terrier==0.10.0)\n  Downloading cwl-eval-1.0.12.tar.gz (31 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->python-terrier==0.10.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->python-terrier==0.10.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->python-terrier==0.10.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->python-terrier==0.10.0) (2024.2.2)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fastrank) (2.21)\nCollecting heapdict (from chest->python-terrier==0.10.0)\n  Downloading HeapDict-1.0.1-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated->python-terrier==0.10.0) (1.14.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->python-terrier==0.10.0) (2.1.3)\nCollecting multiset<3.0,>=2.0 (from matchpy->python-terrier==0.10.0)\n  Downloading multiset-2.1.1-py2.py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->python-terrier==0.10.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->python-terrier==0.10.0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->python-terrier==0.10.0) (2023.4)\nRequirement already satisfied: patsy>=0.5.4 in /opt/conda/lib/python3.10/site-packages (from statsmodels->python-terrier==0.10.0) (0.5.6)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels->python-terrier==0.10.0) (21.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4>=4.4.1->ir_datasets>=0.3.2->python-terrier==0.10.0) (2.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.3->statsmodels->python-terrier==0.10.0) (3.1.1)\nCollecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir_datasets>=0.3.2->python-terrier==0.10.0)\n  Downloading cbor-1.0.0.tar.gz (20 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hDownloading nptyping-1.4.4-py3-none-any.whl (31 kB)\nDownloading fastrank-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ir_datasets-0.5.6-py3-none-any.whl (335 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.2/335.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pytrec_eval_terrier-0.5.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading matchpy-0.5.5-py3-none-any.whl (69 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading inscriptis-2.5.0-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiset-2.1.1-py2.py3-none-any.whl (8.8 kB)\nDownloading pyautocorpus-0.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (379 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\nDownloading typish-1.9.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unlzw3-0.2.2-py3-none-any.whl (6.1 kB)\nDownloading warc3_wet-0.2.3-py3-none-any.whl (13 kB)\nDownloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\nBuilding wheels for collected packages: python-terrier, ir_measures, chest, wget, cwl-eval, warc3-wet-clueweb09, zlib-state, cbor\n  Building wheel for python-terrier (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for python-terrier: filename=python_terrier-0.10.0-py3-none-any.whl size=115532 sha256=fa4030b7afd5726c0e9c4f612cd0a759ebbb736038bc8e180af628ef44452e73\n  Stored in directory: /root/.cache/pip/wheels/79/7c/8f/679a982895c53af35178eceda648a4bc9a9af6af5542e31a0e\n  Building wheel for ir_measures (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ir_measures: filename=ir_measures-0.3.3-py3-none-any.whl size=61182 sha256=c8287cd390f49530d1d1801460dec49680073023d515fe270c73659e961b203e\n  Stored in directory: /root/.cache/pip/wheels/9f/0e/22/718279f23fef1673a4c5e433881c25080a6afaa147e007183e\n  Building wheel for chest (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for chest: filename=chest-0.2.3-py3-none-any.whl size=7612 sha256=88801a7e627282a4a770370295c88f5807439d66d401872796b70f0c7d5f7698\n  Stored in directory: /root/.cache/pip/wheels/88/cf/99/4773b31f855f9ecedc32a0ae400f7a4a3001b37c439b6d1a73\n  Building wheel for wget (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=d90afb1750ee50722ec56979a62826065e5a44b6a6e3aa1df12988a72c19a2a6\n  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n  Building wheel for cwl-eval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cwl-eval: filename=cwl_eval-1.0.12-py3-none-any.whl size=38068 sha256=af681c616f2a205c56cbfbc5a64049432f869c0f1676593ff266568a59352c64\n  Stored in directory: /root/.cache/pip/wheels/3d/c1/94/94a3e5379b1aa8fb7c7f1ad1956305d5edc98ef745b6067d87\n  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=10e691f4fad37d7c235dd1f90db2f10c53ce22b5cbe64a7cfbe8681e3f8bdcdb\n  Stored in directory: /root/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n  Building wheel for zlib-state (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for zlib-state: filename=zlib_state-0.1.6-cp310-cp310-linux_x86_64.whl size=11419 sha256=70df315165e7f5e96c7a3b1b72b8137ebef0aadea7de7837700c8244a718b399\n  Stored in directory: /root/.cache/pip/wheels/32/72/7e/aff80f26e926b6e1fb08dfb52aba03c0e058f5e2258deb50a9\n  Building wheel for cbor (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=23238 sha256=d0887bd5879914bd29ebd8e3f4814c986be8d579f80b91a76b5014419d619775\n  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\nSuccessfully built python-terrier ir_measures chest wget cwl-eval warc3-wet-clueweb09 zlib-state cbor\nInstalling collected packages: wget, warc3-wet-clueweb09, warc3-wet, typish, pyjnius, multiset, ijson, heapdict, cbor, zlib-state, unlzw3, trec-car-tools, pytrec_eval_terrier, pyautocorpus, nptyping, matchpy, cwl-eval, chest, ir_measures, inscriptis, fastrank, ir_datasets, python-terrier\nSuccessfully installed cbor-1.0.0 chest-0.2.3 cwl-eval-1.0.12 fastrank-0.8.0 heapdict-1.0.1 ijson-3.2.3 inscriptis-2.5.0 ir_datasets-0.5.6 ir_measures-0.3.3 matchpy-0.5.5 multiset-2.1.1 nptyping-1.4.4 pyautocorpus-0.1.12 pyjnius-1.6.1 python-terrier-0.10.0 pytrec_eval_terrier-0.5.6 trec-car-tools-2.6 typish-1.9.3 unlzw3-0.2.2 warc3-wet-0.2.3 warc3-wet-clueweb09-0.2.5 wget-3.2 zlib-state-0.1.6\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install --upgrade git+https://github.com/Georgetown-IR-Lab/OpenNIR","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sRDXt2WiBNih","outputId":"d2940d6f-f8c6-4c02-ff38-44a62f187340","execution":{"iopub.status.busy":"2024-03-30T12:25:39.219613Z","iopub.execute_input":"2024-03-30T12:25:39.220058Z","iopub.status.idle":"2024-03-30T12:25:39.225436Z","shell.execute_reply.started":"2024-03-30T12:25:39.220018Z","shell.execute_reply":"2024-03-30T12:25:39.224194Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport json\nimport pyterrier as pt\nimport random","metadata":{"id":"EYhewvEjL-7Y","execution":{"iopub.status.busy":"2024-03-30T12:25:39.226821Z","iopub.execute_input":"2024-03-30T12:25:39.227310Z","iopub.status.idle":"2024-03-30T12:25:39.452920Z","shell.execute_reply.started":"2024-03-30T12:25:39.227266Z","shell.execute_reply":"2024-03-30T12:25:39.451452Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#UNCOMMENT THE FOLLOWING LINE TO USE EITHER THE TVR DATASET OR THE QVH DATASET\n\ndataset_choice = \"TVR\"\n# dataset_choice = \"QVH\"","metadata":{"id":"nKsBbMKjEepz","execution":{"iopub.status.busy":"2024-03-30T12:25:39.460010Z","iopub.execute_input":"2024-03-30T12:25:39.460641Z","iopub.status.idle":"2024-03-30T12:25:39.470333Z","shell.execute_reply.started":"2024-03-30T12:25:39.460600Z","shell.execute_reply":"2024-03-30T12:25:39.469123Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Paths to JSONL files on Colab\n# if dataset_choice == \"TVR\":\n#    jsonl_train_path = '/content/drive/MyDrive/IR/text_data/tvr_train_release.jsonl'\n#    jsonl_val_path = '/content/drive/MyDrive/IR/text_data/tvr_val_release.jsonl'\n#    subs_path = '/content/drive/MyDrive/IR/text_data/tvqa_preprocessed_subtitles.jsonl'\n\n# elif dataset_choice == \"QVH\":\n#    jsonl_train_path = \"/content/drive/MyDrive/IR/text_data_QVH/highlight_train_release.jsonl\"\n#    subs_path = \"/content/drive/MyDrive/IR/text_data_QVH/subs_train.jsonl\"","metadata":{"id":"UruQwRMsOrNj","execution":{"iopub.status.busy":"2024-03-30T12:25:39.472274Z","iopub.execute_input":"2024-03-30T12:25:39.472783Z","iopub.status.idle":"2024-03-30T12:25:39.482937Z","shell.execute_reply.started":"2024-03-30T12:25:39.472738Z","shell.execute_reply":"2024-03-30T12:25:39.481722Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Paths to JSONL files\nif dataset_choice == \"TVR\":\n    jsonl_train_path = '/kaggle/input/tvretrieval/tvr_train_release.jsonl'\n    jsonl_val_path = '/kaggle/input/tvretrieval/tvr_val_release.jsonl'\n    subs_path = '/kaggle/input/tvretrieval/tvqa_preprocessed_subtitles.jsonl'\n\nelif dataset_choice == \"QVH\":\n    jsonl_train_path = \"text_data_QVH/highlight_train_release.jsonl\"\n    subs_path = \"text_data_QVH/subs_train.jsonl\"","metadata":{"id":"W17JgCyFL-7Z","execution":{"iopub.status.busy":"2024-03-30T12:25:39.484888Z","iopub.execute_input":"2024-03-30T12:25:39.485383Z","iopub.status.idle":"2024-03-30T12:25:39.495060Z","shell.execute_reply.started":"2024-03-30T12:25:39.485337Z","shell.execute_reply":"2024-03-30T12:25:39.494063Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Load subtitles into a dictionary for quick access\nsubtitles_dict = {}\nif dataset_choice == \"TVR\":\n    with open(subs_path, 'r') as subs_file:\n        for line in subs_file:\n            sub_data = json.loads(line)\n            subtitles_dict[sub_data['vid_name']] = sub_data['sub']\nelif dataset_choice == \"QVH\":\n    with open(subs_path, 'r') as subs_file:\n        for line in subs_file:\n            sub_data = json.loads(line)\n            triple = sub_data['vid'].split(\"_\")\n            name = triple[0:-2]\n            #turn the list name into a string\n            name = \"\".join(name)\n            if name not in subtitles_dict:\n                subtitles_dict[name] = [(float(triple[-2]) + sub_data[\"relevant_windows\"][0][0], float(triple[-2]) + sub_data[\"relevant_windows\"][0][1], sub_data['query'])]\n            else:\n                subtitles_dict[name].append((float(triple[-2]) + sub_data[\"relevant_windows\"][0][0], float(triple[-2]) + sub_data[\"relevant_windows\"][0][1], sub_data['query']))","metadata":{"id":"L6VZMDuDL-7Z","execution":{"iopub.status.busy":"2024-03-30T12:25:39.496775Z","iopub.execute_input":"2024-03-30T12:25:39.497257Z","iopub.status.idle":"2024-03-30T12:25:40.721577Z","shell.execute_reply.started":"2024-03-30T12:25:39.497213Z","shell.execute_reply":"2024-03-30T12:25:40.720292Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Function to find matching subtitles in TVR case\ndef find_matching_subtitles(vid_name, ts_range, subtitles_dict):\n    matching_subs = []\n    if vid_name in subtitles_dict:\n        for subtitle in subtitles_dict[vid_name]:\n            if (ts_range[0] <= subtitle['start'] <= ts_range[1]) or (ts_range[0] <= subtitle['end'] <= ts_range[1]) or (subtitle['start'] <= ts_range[0] and subtitle['end'] >= ts_range[1]):\n                matching_subs.append(subtitle['text'])\n    return matching_subs","metadata":{"id":"UkWQOjjYL-7Z","execution":{"iopub.status.busy":"2024-03-30T12:25:40.723274Z","iopub.execute_input":"2024-03-30T12:25:40.723765Z","iopub.status.idle":"2024-03-30T12:25:40.732291Z","shell.execute_reply.started":"2024-03-30T12:25:40.723708Z","shell.execute_reply":"2024-03-30T12:25:40.730615Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def parse_jsonl_TVR(jsonl_path, split_type):\n    # Initialize empty lists for your data\n    queries_data = []\n    documents_data = []\n    query_rankings_data = []\n\n    with open(jsonl_path, 'r') as file:\n        for idx, line in enumerate(file):\n            data = json.loads(line)\n            # drop non text-based queries\n            if data['type'] not in ['t']:\n                continue\n\n            # Find matching subtitles\n            matching_subs = find_matching_subtitles(data['vid_name'], data['ts'], subtitles_dict)\n\n            if matching_subs == []:\n                continue\n\n            # Extract data for the Query Set DataFrame\n            queries_data.append({'qid': str(data['desc_id']), 'query': data['desc']})\n\n            # Extract data for the Documents Set DataFrame, including matching subtitles\n            documents_data.append({'docno': split_type + str(idx), 'vid_name': data['vid_name'], 'ts': data['ts'],\n                                'duration': data['duration'], 'type': data['type'], 'text': \"\".join(matching_subs)})\n\n            # Extract data for the Query Rankings DataFrame\n            query_rankings_data.append({'qid': str(data[\"desc_id\"]), 'query': data['desc'], 'docno': split_type + str(idx), 'rank': 1, 'score': 1.0})\n\n    return queries_data, documents_data, query_rankings_data\n\ndef parse_jsonl_QVH(jsonl_path):\n    queries_data = []\n    documents_data = []\n    query_rankings_data = []\n    with open(jsonl_path, 'r') as file:\n        for idx,line in enumerate(file):\n\n            # Load the JSON object from the line\n            data = json.loads(line)\n\n            triple = data[\"vid\"].split(\"_\")\n            document_name = triple[0:-2]\n            document_name = \"\".join(document_name)\n            start_time = float(triple[-2])\n            end_time = float(triple[-1])\n\n            if document_name not in subtitles_dict:\n                #print(\"Document not found in subtitles: \", document_name)\n                continue\n\n            momentaneus_rank =[]\n            count = 0\n            for id,relevant_window in enumerate(data[\"relevant_windows\"]):\n                ts = [start_time+relevant_window[0], start_time+relevant_window[1]]\n                subs = [sub for sub in subtitles_dict[document_name] if sub[0] <= ts[1] and ts[0] <= sub[1]]\n                if len(subs) == 0:\n                    #print(\"No subtitles found for \", document_name, \" at time \", ts)\n                    continue\n                count += 1\n                documents_data.append({\"docno\" : str(idx) +\"_\"+str(ts[0]) + \"_\" + str(ts[1]), \"vid_name\" : document_name, \"ts\": ts, \"duration\": data[\"duration\"], \"text\": \"\".join([sub[2] for sub in subs])})\n                scores = [data[\"saliency_scores\"][i]  for i,clip_id in enumerate(data[\"relevant_clip_ids\"]) if clip_id*2 >= relevant_window[0] and clip_id*2 <= relevant_window[1]]\n                if len(scores) == 0:\n                    #print(\"No scores found for \", document_name, \" at time \", ts)\n                    continue\n                #each entry of scores is a triple of integers. Create a variable score which is the average of all the scores\n                score = 0 if len(scores) ==0 else sum(sum(scores[i]) for i in range(len(scores)))/(3*len(scores))\n\n                momentaneus_rank.append({\"qid\" : str(data[\"qid\"]), \"query\": data[\"query\"] , \"docno\" : str(idx) +\"_\"+str(ts[0]) + \"_\" + str(ts[1]), \"score\": score, \"rank\":1})\n\n            if count == 0:\n                #print(\"No relevant windows found for \", document_name)\n                continue\n            #adjust the rank of the momentaneus_rank based on the score\n            momentaneus_rank = sorted(momentaneus_rank, key=lambda x: x[\"score\"], reverse=True)\n            for i in range(len(momentaneus_rank)):\n                momentaneus_rank[i][\"rank\"] = i+1\n            queries_data.append({\"qid\" : str(data[\"qid\"]), \"query\": data[\"query\"]})\n            query_rankings_data.extend(momentaneus_rank)\n\n    return queries_data, documents_data, query_rankings_data","metadata":{"id":"HDx8ntjxL-7a","execution":{"iopub.status.busy":"2024-03-30T12:25:40.733860Z","iopub.execute_input":"2024-03-30T12:25:40.734241Z","iopub.status.idle":"2024-03-30T12:25:40.755066Z","shell.execute_reply.started":"2024-03-30T12:25:40.734200Z","shell.execute_reply":"2024-03-30T12:25:40.753815Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\nif dataset_choice == \"TVR\":\n    queries_data_train, documents_data_train, query_rankings_data_train = parse_jsonl_TVR(jsonl_train_path, \"t\")\n    queries_data_val, documents_data_val, query_rankings_data_val = parse_jsonl_TVR(jsonl_val_path, \"v\")\n    #have to create a test set; to do it, extract a random 10% of the train set\n    random.seed(42)\n    query_rankings_data_test = random.sample(query_rankings_data_train, int(len(query_rankings_data_train)*0.1))\n    query_rankings_data_train = [query for query in query_rankings_data_train if query not in query_rankings_data_test]\n    queries_data_test = [query for query in queries_data_train if query[\"qid\"] in [query[\"qid\"] for query in query_rankings_data_test]]\n    queries_data_train = [query for query in queries_data_train if query not in queries_data_test]\n    documents_data_test = [doc for doc in documents_data_train if doc[\"docno\"] in [query[\"docno\"] for query in query_rankings_data_test]]\n    documents_data_train = [doc for doc in documents_data_train if doc not in documents_data_test]\n\nelif dataset_choice == \"QVH\":\n    queries_data_train, documents_data_train, query_rankings_data_train = parse_jsonl_QVH(jsonl_train_path)\n    #have to create a val set; to do it, extract a random 10% of the train set\n    random.seed(42)\n    query_rankings_data_val = random.sample(query_rankings_data_train, int(len(query_rankings_data_train)*0.1))\n    query_rankings_data_train = [query for query in query_rankings_data_train if query not in query_rankings_data_val]\n    queries_data_val = [query for query in queries_data_train if query[\"qid\"] in [query[\"qid\"] for query in query_rankings_data_val]]\n    queries_data_train = [query for query in queries_data_train if query not in queries_data_val]\n    documents_data_val = [doc for doc in documents_data_train if doc[\"docno\"] in [query[\"docno\"] for query in query_rankings_data_val]]\n    documents_data_train = [doc for doc in documents_data_train if doc not in documents_data_val]\n    #have to create a test set; to do it, extract a random 10% of the train set\n    random.seed(42)\n    query_rankings_data_test = random.sample(query_rankings_data_train, int(len(query_rankings_data_train)*0.1))\n    query_rankings_data_train = [query for query in query_rankings_data_train if query not in query_rankings_data_test]\n    queries_data_test = [query for query in queries_data_train if query[\"qid\"] in [query[\"qid\"] for query in query_rankings_data_test]]\n    queries_data_train = [query for query in queries_data_train if query not in queries_data_test]\n    documents_data_test = [doc for doc in documents_data_train if doc[\"docno\"] in [query[\"docno\"] for query in query_rankings_data_test]]\n    documents_data_train = [doc for doc in documents_data_train if doc not in documents_data_test]\n\n","metadata":{"id":"Ae33k1XsEep2","execution":{"iopub.status.busy":"2024-03-30T12:25:40.758672Z","iopub.execute_input":"2024-03-30T12:25:40.759552Z","iopub.status.idle":"2024-03-30T12:25:44.224448Z","shell.execute_reply.started":"2024-03-30T12:25:40.759511Z","shell.execute_reply":"2024-03-30T12:25:44.223172Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Create DataFrames for the Query Set, Documents Set, and Query Rankings\nqueries_train_df = pd.DataFrame(queries_data_train)\ndocuments_train_df = pd.DataFrame(documents_data_train)\n\nqueries_val_df = pd.DataFrame(queries_data_val)\ndocuments_val_df = pd.DataFrame(documents_data_val)\n\nqueries_test_df = pd.DataFrame(queries_data_test)\ndocuments_test_df = pd.DataFrame(documents_data_test)\n\nq_rels = pd.concat([pd.DataFrame(query_rankings_data_train), pd.DataFrame(query_rankings_data_val), pd.DataFrame(query_rankings_data_test)]).reset_index(drop=True)\n\n#print length of the dataframes\nprint(\"Train set:\")\nprint(\"Queries: \", len(queries_train_df))\nprint(\"Documents: \", len(documents_train_df))\n\nprint(\"Val set:\")\nprint(\"Queries: \", len(queries_val_df))\nprint(\"Documents: \", len(documents_val_df))\n\nprint(\"Test set:\")\nprint(\"Queries: \", len(queries_test_df))\nprint(\"Documents: \", len(documents_test_df))\n\nprint(\"Query Rankings: \", len(q_rels))\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTiDgmaqL-7a","outputId":"b7e64317-7faf-47c4-e8a9-20be5a030ea7","execution":{"iopub.status.busy":"2024-03-30T12:25:44.226167Z","iopub.execute_input":"2024-03-30T12:25:44.226616Z","iopub.status.idle":"2024-03-30T12:25:44.295918Z","shell.execute_reply.started":"2024-03-30T12:25:44.226576Z","shell.execute_reply":"2024-03-30T12:25:44.294951Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Train set:\nQueries:  7110\nDocuments:  7110\nVal set:\nQueries:  957\nDocuments:  957\nTest set:\nQueries:  790\nDocuments:  790\nQuery Rankings:  8857\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### First Stage Retrieval [TODO: BOX]\nThe following part of the code will define three different first stage retrieval pipelines as an input for the trained model.","metadata":{"id":"NCaV5vcXL-7a"}},{"cell_type":"code","source":"!ls -la /usr/lib/jvm/java-11-openjdk-amd64\nimport os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n\nif not pt.started():\n    pt.init()","metadata":{"id":"5-SsgPJwVMXw","execution":{"iopub.status.busy":"2024-03-30T12:25:44.297369Z","iopub.execute_input":"2024-03-30T12:25:44.297922Z","iopub.status.idle":"2024-03-30T12:25:47.986516Z","shell.execute_reply.started":"2024-03-30T12:25:44.297890Z","shell.execute_reply":"2024-03-30T12:25:47.984956Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"total 32\ndrwxr-xr-x  7 root root 4096 Feb 22 12:31 .\ndrwxr-xr-x  3 root root 4096 Feb 22 12:31 ..\ndrwxr-xr-x  2 root root 4096 Feb 22 12:31 bin\ndrwxr-xr-x  4 root root 4096 Feb 22 12:31 conf\nlrwxrwxrwx  1 root root   42 Oct 19 07:55 docs -> ../../../share/doc/openjdk-11-jre-headless\ndrwxr-xr-x 73 root root 4096 Feb 22 12:31 legal\ndrwxr-xr-x  6 root root 4096 Feb 22 12:31 lib\ndrwxr-xr-x  4 root root 4096 Feb 22 12:31 man\n-rw-r--r--  1 root root 1248 Oct 19 07:55 release\nterrier-assemblies 5.8 jar-with-dependencies not found, downloading to /root/.pyterrier...\nDone\nterrier-python-helper 0.0.8 jar not found, downloading to /root/.pyterrier...\nDone\n","output_type":"stream"},{"name":"stderr","text":"PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n\nNo etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create an index\nfrom pathlib import Path\n\nindexer = pt.IterDictIndexer(\n    \"./index_path/\",\n    meta={\n        \"docno\": 64,\n        \"vid_name\": 64,\n        \"text\": 131072,\n    },\n    stemmer=\"porter\",\n    stopwords=\"terrier\",\n    overwrite=True,\n    # type=pt.index.IndexingType.MEMORY,\n)","metadata":{"id":"Xx55BjIGfNNa","execution":{"iopub.status.busy":"2024-03-30T12:25:47.989169Z","iopub.execute_input":"2024-03-30T12:25:47.989943Z","iopub.status.idle":"2024-03-30T12:25:48.191011Z","shell.execute_reply.started":"2024-03-30T12:25:47.989892Z","shell.execute_reply":"2024-03-30T12:25:48.189716Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"joint_documents_set_df = pd.concat([documents_train_df, documents_val_df, documents_test_df])\n\nprint(\"Length: \", len(joint_documents_set_df))","metadata":{"id":"T1W-_BFDjpqS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"657431e1-1296-4391-9ac1-113827b51bcd","execution":{"iopub.status.busy":"2024-03-30T12:25:48.192321Z","iopub.execute_input":"2024-03-30T12:25:48.192651Z","iopub.status.idle":"2024-03-30T12:25:48.206436Z","shell.execute_reply.started":"2024-03-30T12:25:48.192624Z","shell.execute_reply":"2024-03-30T12:25:48.205073Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Length:  8857\n","output_type":"stream"}]},{"cell_type":"code","source":"indexed = indexer.index(\n    joint_documents_set_df.to_dict(orient=\"records\")\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_PnpogfjpqS","outputId":"6909ba8e-62af-4f78-da7d-59ce66637ba4","execution":{"iopub.status.busy":"2024-03-30T12:25:48.208305Z","iopub.execute_input":"2024-03-30T12:25:48.208690Z","iopub.status.idle":"2024-03-30T12:25:57.446882Z","shell.execute_reply.started":"2024-03-30T12:25:48.208656Z","shell.execute_reply":"2024-03-30T12:25:57.445501Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"12:25:52.092 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (t24499) - further warnings are suppressed\n12:25:57.412 [ForkJoinPool-1-worker-3] WARN org.terrier.structures.indexing.Indexer - Indexed 2 empty documents\n","output_type":"stream"}]},{"cell_type":"code","source":"#These are some examples, not necessarily the best ones. Experiment with different models\n\n# Initialize BatchRetrieve with the created index and specify BM25 as the weighting model\nfirst_stage_bm25 = pt.BatchRetrieve(\n    indexed,\n    wmodel=\"BM25\",\n    num_results=100,\n    metadata=[\"docno\", \"vid_name\", \"text\"]\n)\n\n# Initialize BatchRetrieve with the created index and specify LemurTF_IDF as the weighting model\nfirst_stage_lemurtfidf = pt.BatchRetrieve(\n    indexed,\n    wmodel=\"LemurTF_IDF\",\n    num_results=100,\n    metadata=[\"docno\", \"vid_name\", \"text\"]\n)\n\n# Initialize BatchRetrieve with the created index and specify Hiemstra_LM as the weighting model\nfirst_stage_hiemstra_lm = pt.BatchRetrieve(\n    indexed,\n    wmodel=\"Hiemstra_LM\",\n    num_results=100,\n    metadata=[\"docno\", \"vid_name\", \"text\"]\n)\n\nfirst_stage_dfic = pt.BatchRetrieve(\n    indexed,\n    wmodel=\"DFIC\",\n    num_results=100,\n    metadata=['docno', 'vid_name', 'text']\n)\n\nfirst_stage_ldg = pt.BatchRetrieve(\n    indexed,\n    wmodel=\"LGD\",\n    num_results=100,\n    metadata=[\"docno\", \"vid_name\", \"text\"]\n)\n\nfirst_stage_in_exp_b2 = pt.BatchRetrieve(\n    indexed,\n    wmodel=\"In_expB2\",\n    num_results=100,\n    metadata=[\"docno\", \"vid_name\", \"text\"]\n)","metadata":{"id":"9xuAPswuVQMe","execution":{"iopub.status.busy":"2024-03-30T12:25:57.454622Z","iopub.execute_input":"2024-03-30T12:25:57.458298Z","iopub.status.idle":"2024-03-30T12:25:57.562264Z","shell.execute_reply.started":"2024-03-30T12:25:57.458232Z","shell.execute_reply":"2024-03-30T12:25:57.560909Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Computing feature\nThe weighting model can be use in [pt.weighting_model.package: http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html)","metadata":{"id":"7vCeCMoUvedO"}},{"cell_type":"code","source":"#We create features for the second stage using the first stage retrievers\n\n#TF-IDF based features\nlemur_tf_idf_retriever = pt.BatchRetrieve(indexed, wmodel=\"LemurTF_IDF\")\nbm25_retriever = pt.BatchRetrieve(indexed, wmodel=\"BM25\")\ntf_idf_retriever = pt.BatchRetrieve(indexed, wmodel=\"TF_IDF\")\n\n#Language model based features\nhiem_retriever = pt.BatchRetrieve(indexed, wmodel=\"Hiemstra_LM\")\ndirichlet_retriever = pt.BatchRetrieve(indexed, wmodel=\"DirichletLM\")\n\n#Divergence from randomness based features\npl2_retriever = pt.BatchRetrieve(indexed, wmodel=\"PL2\")\ndph_retriever = pt.BatchRetrieve(indexed, wmodel=\"DPH\")\ndlh_retriever = pt.BatchRetrieve(indexed, wmodel=\"DLH\")\n\n#Can add more!\ncoordinate_match_retriever = pt.BatchRetrieve(indexed, wmodel=\"CoordinateMatch\")\njs_kls_retrieveer = pt.BatchRetrieve(indexed, wmodel=\"Js_KLs\")\n","metadata":{"id":"QTBZtHYLy_fH","execution":{"iopub.status.busy":"2024-03-30T12:25:57.568937Z","iopub.execute_input":"2024-03-30T12:25:57.572413Z","iopub.status.idle":"2024-03-30T12:25:57.688668Z","shell.execute_reply.started":"2024-03-30T12:25:57.572349Z","shell.execute_reply":"2024-03-30T12:25:57.687278Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# PIPELINES WITH FSR AND FEATURES\n\n#Can test many possibilities, i just put some examples here\n\nbm25_pipeline = ~first_stage_bm25 >> (\n   tf_idf_retriever ** coordinate_match_retriever ** dirichlet_retriever ** js_kls_retrieveer ** bm25_retriever\n)\n\n\nlemurtf_idf_pipeline = ~first_stage_lemurtfidf >> (\n    pl2_retriever ** dph_retriever ** hiem_retriever ** coordinate_match_retriever ** dirichlet_retriever ** js_kls_retrieveer\n)\n\nhiem_lm_pipeline = ~hiem_retriever >> (\n    pl2_retriever ** dph_retriever ** tf_idf_retriever ** coordinate_match_retriever ** dirichlet_retriever ** js_kls_retrieveer\n)\n\n#NOTE: i believe we should not use the same first stage retriever for features AND for the first stage retrieval","metadata":{"id":"AYrqwBx1vVn_","execution":{"iopub.status.busy":"2024-03-30T12:25:57.690937Z","iopub.execute_input":"2024-03-30T12:25:57.691915Z","iopub.status.idle":"2024-03-30T12:25:57.709718Z","shell.execute_reply.started":"2024-03-30T12:25:57.691866Z","shell.execute_reply":"2024-03-30T12:25:57.707766Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Prepare the queries for the pipeline, remove special characters and extra spaces\nprepared_trainqueries = queries_train_df\nprepared_trainqueries['query'] = prepared_trainqueries['query'].str.replace('[\\'\"?!]', ' ', regex=True)\nprepared_trainqueries['query'] = prepared_trainqueries['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\nprepared_trainqueries['query'] = prepared_trainqueries['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n\nprepared_train_qrels = pd.DataFrame(query_rankings_data_train)\nprepared_train_qrels['query'] = prepared_train_qrels['query'].str.replace('[\\'\"?!]', ' ', regex=True)\nprepared_train_qrels['query'] = prepared_train_qrels['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\nprepared_train_qrels['query'] = prepared_train_qrels['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n\nprepared_train_qrels['label'] = prepared_train_qrels['score']\n\nprepared_train_qrels['label'] = prepared_train_qrels['label'].astype(int)\n\nprepared_val_qrels = pd.DataFrame(query_rankings_data_val)\nprepared_val_qrels['query'] = prepared_val_qrels['query'].str.replace('[\\'\"?!]', ' ', regex=True)\nprepared_val_qrels['query'] = prepared_val_qrels['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\nprepared_val_qrels['query'] = prepared_val_qrels['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n\nprepared_val_qrels['label'] = prepared_val_qrels['score']\n\nprepared_val_qrels['label'] = prepared_val_qrels['label'].astype(int)\n\nprepared_test_qrels = pd.DataFrame(query_rankings_data_test)\nprepared_test_qrels['query'] = prepared_test_qrels['query'].str.replace('[\\'\"?!]', ' ', regex=True)\nprepared_test_qrels['query'] = prepared_test_qrels['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\nprepared_test_qrels['query'] = prepared_test_qrels['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n\nprepared_test_qrels['label'] = prepared_test_qrels['score']\n\nprepared_test_qrels['label'] = prepared_test_qrels['label'].astype(int)\n\nprepared_qrels = q_rels\nprepared_qrels['query'] = prepared_qrels['query'].str.replace('[\\'\"?!]', ' ', regex=True)\nprepared_qrels['query'] = prepared_qrels['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\nprepared_qrels['query'] = prepared_qrels['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n\nprepared_qrels['label'] = prepared_qrels['score']\n\nprepared_qrels['label'] = prepared_qrels['label'].astype(int)\n\nprepared_valqueries = queries_val_df.reset_index()\nprepared_valqueries['query'] = prepared_valqueries['query'].str.replace('[\\'\"?!]', ' ', regex=True)\nprepared_valqueries['query'] = prepared_valqueries['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n\nprepared_valqueries['query'] = prepared_valqueries['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n\n#test set\nprepared_testqueries = queries_test_df.reset_index()\nprepared_testqueries['query'] = prepared_testqueries['query'].str.replace('[\\'\"?!]', ' ', regex=True)\nprepared_testqueries['query'] = prepared_testqueries['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\nprepared_testqueries['query'] = prepared_testqueries['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n","metadata":{"id":"QE1WrfC8zJjm","execution":{"iopub.status.busy":"2024-03-30T12:25:57.711462Z","iopub.execute_input":"2024-03-30T12:25:57.711843Z","iopub.status.idle":"2024-03-30T12:25:58.015869Z","shell.execute_reply.started":"2024-03-30T12:25:57.711813Z","shell.execute_reply":"2024-03-30T12:25:58.014424Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Storage format: .csv or trec\n\ntrec(https://pyterrier.readthedocs.io/en/latest/io.html): The pt io format, but it doesn't contain feature.","metadata":{"id":"xLeXGDj8rGcx"}},{"cell_type":"code","source":"from sklearn.svm import SVR\nimport xgboost as xgb\nimport fastrank\n\nindex = pt.IndexFactory.of(\"./index_path\")\n\nfsr_pipelines = [\n    #{\n    #    'pipe': lemurtf_idf_pipeline,\n    #    'name': 'LemurTF_IDF'\n    #},\n    #{\n    #    'pipe': bm25_pipeline,\n    #    'name': 'BM25'\n    #},\n    #{\n    #    'pipe': hiem_lm_pipeline,\n    #    'name': 'Hiemstra LM'\n    #}\n]\n\nlearned_models = [\n    # {\n    #     'model': SVR(),\n    #     'form': 'reg',\n    #     'name': 'SVR',\n    # },\n    {\n        'model': xgb.XGBRanker(tree_method=\"hist\", objective=\"rank:ndcg\"),\n        'form': 'ltr',\n        'name': 'XGBoost (NDCG)',\n    },\n    #{\n    #    'model': xgb.XGBRanker(tree_method=\"hist\", lambdarank_num_pair_per_sample=8, objective=\"rank:pairwise\", lambdarank_pair_method=\"topk\"),\n    #    'form': 'ltr',\n    #    'name': 'XGBoost (Pariwise)'\n    #}\n    # {\n    #     'model': xgb.XGBRanker(tree_method=\"hist\", objective=\"rank:map\"),\n    #     'form': 'ltr',\n    #     'name': 'XGBoost (MAP)',\n    # },\n    #{\n    #    'model': fastrank.TrainRequest.coordinate_ascent(),\n    #    'form': 'fastrank',\n    #    'name': 'FastRank Coordinate Ascent',\n    #},\n    #{\n    #    'model': fastrank.TrainRequest.random_forest(),\n    #    'form': 'fastrank',\n    #    'name': 'FastRank Random Forest',\n    #}\n  ]","metadata":{"id":"RGv0tMvLEep6","execution":{"iopub.status.busy":"2024-03-30T12:25:58.017359Z","iopub.execute_input":"2024-03-30T12:25:58.017724Z","iopub.status.idle":"2024-03-30T12:25:59.295379Z","shell.execute_reply.started":"2024-03-30T12:25:58.017693Z","shell.execute_reply":"2024-03-30T12:25:59.294180Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from pyterrier.measures import *\n\ntrained_models = [first_stage_bm25, first_stage_lemurtfidf, first_stage_hiemstra_lm, first_stage_dfic,  first_stage_ldg, first_stage_in_exp_b2]\nnames = ['BM25', 'LemurTF_IDF', 'Hiemstra LM', 'DFIC', 'LGD', 'In Exp  B2']\neval_metrics = [\n    nDCG @ 1, nDCG @ 3, nDCG @ 5, nDCG @ 10, nDCG @ 30,\n    RR @ 1,   RR @ 3,   RR @ 5,   RR @ 10, RR @ 30,\n    MAP, NumRelRet, Judged @ 1,Judged @ 3, Judged @ 5\n]\n\nfor fsr in fsr_pipelines:\n    for model in learned_models:\n        names.append(f\"{fsr['name']} >> {model['name']}\")\n        print(names[-1])\n        if 'form' in model:\n          pipe = fsr['pipe'] >> pt.ltr.apply_learned_model(model['model'], form=model['form'])\n        else:\n          pipe = fsr['pipe'] >> pt.ltr.apply_learned_model(model['model'])\n        pipe.fit(\n            prepared_trainqueries,\n            prepared_train_qrels,\n            prepared_valqueries,\n            prepared_val_qrels\n        )\n        trained_models.append(pipe)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lOrma3FeEep6","outputId":"c89521e4-6c24-4e33-e240-33abc9817088","execution":{"iopub.status.busy":"2024-03-30T12:25:59.297283Z","iopub.execute_input":"2024-03-30T12:25:59.298074Z","iopub.status.idle":"2024-03-30T12:25:59.309337Z","shell.execute_reply.started":"2024-03-30T12:25:59.298024Z","shell.execute_reply":"2024-03-30T12:25:59.308108Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from pyterrier.measures import nDCG, RR, MAP\n\npt.Experiment(\n    trained_models,\n    prepared_testqueries,\n    prepared_test_qrels,\n    names=names,\n    eval_metrics=eval_metrics,\n)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"LZNp8z2VMYsN","outputId":"2e62f92b-f37a-4f16-900e-134b4fceef22","execution":{"iopub.status.busy":"2024-03-30T12:25:59.313622Z","iopub.execute_input":"2024-03-30T12:25:59.314563Z","iopub.status.idle":"2024-03-30T12:35:08.649934Z","shell.execute_reply.started":"2024-03-30T12:25:59.314494Z","shell.execute_reply":"2024-03-30T12:35:08.648760Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"          name    nDCG@1    nDCG@3    nDCG@5   nDCG@10   nDCG@30      RR@1  \\\n0         BM25  0.193671  0.239239  0.251602  0.269062  0.289388  0.193671   \n1  LemurTF_IDF  0.175949  0.221186  0.235462  0.249067  0.270555  0.175949   \n2  Hiemstra LM  0.183544  0.226084  0.237523  0.253003  0.271873  0.181013   \n3         DFIC  0.179747  0.217057  0.229476  0.251819  0.269983  0.179747   \n4          LGD  0.173418  0.214526  0.230538  0.247698  0.268238  0.173418   \n5   In Exp  B2  0.192405  0.244966  0.257873  0.273979  0.295754  0.192405   \n\n       RR@3      RR@5     RR@10     RR@30        AP  NumRet(rel=1)  Judged@1  \\\n0  0.228270  0.235042  0.242186  0.247235  0.249689          451.0  0.193671   \n1  0.210127  0.218165  0.223643  0.228794  0.230988          429.0  0.175949   \n2  0.213924  0.220506  0.226934  0.231605  0.235654          430.0  0.181013   \n3  0.208439  0.215274  0.224529  0.228980  0.231538          439.0  0.179747   \n4  0.204641  0.213439  0.220754  0.225674  0.228150          437.0  0.173418   \n5  0.232068  0.239156  0.245546  0.250858  0.253325          463.0  0.192405   \n\n   Judged@3  Judged@5  \n0  0.090295  0.060253  \n1  0.084388  0.057468  \n2  0.084810  0.056709  \n3  0.080591  0.054430  \n4  0.081013  0.056456  \n5  0.094093  0.062785  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>nDCG@1</th>\n      <th>nDCG@3</th>\n      <th>nDCG@5</th>\n      <th>nDCG@10</th>\n      <th>nDCG@30</th>\n      <th>RR@1</th>\n      <th>RR@3</th>\n      <th>RR@5</th>\n      <th>RR@10</th>\n      <th>RR@30</th>\n      <th>AP</th>\n      <th>NumRet(rel=1)</th>\n      <th>Judged@1</th>\n      <th>Judged@3</th>\n      <th>Judged@5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BM25</td>\n      <td>0.193671</td>\n      <td>0.239239</td>\n      <td>0.251602</td>\n      <td>0.269062</td>\n      <td>0.289388</td>\n      <td>0.193671</td>\n      <td>0.228270</td>\n      <td>0.235042</td>\n      <td>0.242186</td>\n      <td>0.247235</td>\n      <td>0.249689</td>\n      <td>451.0</td>\n      <td>0.193671</td>\n      <td>0.090295</td>\n      <td>0.060253</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LemurTF_IDF</td>\n      <td>0.175949</td>\n      <td>0.221186</td>\n      <td>0.235462</td>\n      <td>0.249067</td>\n      <td>0.270555</td>\n      <td>0.175949</td>\n      <td>0.210127</td>\n      <td>0.218165</td>\n      <td>0.223643</td>\n      <td>0.228794</td>\n      <td>0.230988</td>\n      <td>429.0</td>\n      <td>0.175949</td>\n      <td>0.084388</td>\n      <td>0.057468</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hiemstra LM</td>\n      <td>0.183544</td>\n      <td>0.226084</td>\n      <td>0.237523</td>\n      <td>0.253003</td>\n      <td>0.271873</td>\n      <td>0.181013</td>\n      <td>0.213924</td>\n      <td>0.220506</td>\n      <td>0.226934</td>\n      <td>0.231605</td>\n      <td>0.235654</td>\n      <td>430.0</td>\n      <td>0.181013</td>\n      <td>0.084810</td>\n      <td>0.056709</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DFIC</td>\n      <td>0.179747</td>\n      <td>0.217057</td>\n      <td>0.229476</td>\n      <td>0.251819</td>\n      <td>0.269983</td>\n      <td>0.179747</td>\n      <td>0.208439</td>\n      <td>0.215274</td>\n      <td>0.224529</td>\n      <td>0.228980</td>\n      <td>0.231538</td>\n      <td>439.0</td>\n      <td>0.179747</td>\n      <td>0.080591</td>\n      <td>0.054430</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LGD</td>\n      <td>0.173418</td>\n      <td>0.214526</td>\n      <td>0.230538</td>\n      <td>0.247698</td>\n      <td>0.268238</td>\n      <td>0.173418</td>\n      <td>0.204641</td>\n      <td>0.213439</td>\n      <td>0.220754</td>\n      <td>0.225674</td>\n      <td>0.228150</td>\n      <td>437.0</td>\n      <td>0.173418</td>\n      <td>0.081013</td>\n      <td>0.056456</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>In Exp  B2</td>\n      <td>0.192405</td>\n      <td>0.244966</td>\n      <td>0.257873</td>\n      <td>0.273979</td>\n      <td>0.295754</td>\n      <td>0.192405</td>\n      <td>0.232068</td>\n      <td>0.239156</td>\n      <td>0.245546</td>\n      <td>0.250858</td>\n      <td>0.253325</td>\n      <td>463.0</td>\n      <td>0.192405</td>\n      <td>0.094093</td>\n      <td>0.062785</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from pyterrier.measures import nDCG, RR, MAP\n\npt.Experiment(\n    trained_models,\n    prepared_valqueries,\n    prepared_val_qrels,\n    names=names,\n    eval_metrics=eval_metrics,\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"vhtfFvM0Eep6","outputId":"6b0eda5a-3fcd-45a8-dbeb-8c451dc077aa","execution":{"iopub.status.busy":"2024-03-30T12:35:08.651530Z","iopub.execute_input":"2024-03-30T12:35:08.652816Z","iopub.status.idle":"2024-03-30T12:45:55.667709Z","shell.execute_reply.started":"2024-03-30T12:35:08.652772Z","shell.execute_reply":"2024-03-30T12:45:55.666282Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"          name    nDCG@1    nDCG@3    nDCG@5   nDCG@10   nDCG@30      RR@1  \\\n0         BM25  0.196447  0.246292  0.264185  0.288406  0.309813  0.197492   \n1  LemurTF_IDF  0.167189  0.227532  0.243763  0.258096  0.281515  0.167189   \n2  Hiemstra LM  0.179728  0.229138  0.244560  0.262100  0.285058  0.179728   \n3         DFIC  0.174504  0.223850  0.238152  0.257576  0.286947  0.174504   \n4          LGD  0.179728  0.226189  0.239857  0.258974  0.288781  0.179728   \n5   In Exp  B2  0.187043  0.255546  0.269169  0.290187  0.312461  0.188088   \n\n       RR@3      RR@5     RR@10     RR@30        AP  NumRet(rel=1)  Judged@1  \\\n0  0.234413  0.243974  0.254232  0.259449  0.261373          573.0  0.197492   \n1  0.211947  0.221351  0.227320  0.233054  0.235721          548.0  0.167189   \n2  0.215778  0.224608  0.231965  0.237554  0.240082          538.0  0.179728   \n3  0.212295  0.220080  0.228004  0.235334  0.237360          556.0  0.174504   \n4  0.215430  0.222745  0.230653  0.238008  0.240123          551.0  0.179728   \n5  0.238419  0.246151  0.255024  0.260360  0.262796          594.0  0.188088   \n\n   Judged@3  Judged@5  \n0  0.093347  0.064577  \n1  0.089516  0.062069  \n2  0.087774  0.060397  \n3  0.085684  0.058098  \n4  0.085684  0.057889  \n5  0.100662  0.067294  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>nDCG@1</th>\n      <th>nDCG@3</th>\n      <th>nDCG@5</th>\n      <th>nDCG@10</th>\n      <th>nDCG@30</th>\n      <th>RR@1</th>\n      <th>RR@3</th>\n      <th>RR@5</th>\n      <th>RR@10</th>\n      <th>RR@30</th>\n      <th>AP</th>\n      <th>NumRet(rel=1)</th>\n      <th>Judged@1</th>\n      <th>Judged@3</th>\n      <th>Judged@5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BM25</td>\n      <td>0.196447</td>\n      <td>0.246292</td>\n      <td>0.264185</td>\n      <td>0.288406</td>\n      <td>0.309813</td>\n      <td>0.197492</td>\n      <td>0.234413</td>\n      <td>0.243974</td>\n      <td>0.254232</td>\n      <td>0.259449</td>\n      <td>0.261373</td>\n      <td>573.0</td>\n      <td>0.197492</td>\n      <td>0.093347</td>\n      <td>0.064577</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LemurTF_IDF</td>\n      <td>0.167189</td>\n      <td>0.227532</td>\n      <td>0.243763</td>\n      <td>0.258096</td>\n      <td>0.281515</td>\n      <td>0.167189</td>\n      <td>0.211947</td>\n      <td>0.221351</td>\n      <td>0.227320</td>\n      <td>0.233054</td>\n      <td>0.235721</td>\n      <td>548.0</td>\n      <td>0.167189</td>\n      <td>0.089516</td>\n      <td>0.062069</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hiemstra LM</td>\n      <td>0.179728</td>\n      <td>0.229138</td>\n      <td>0.244560</td>\n      <td>0.262100</td>\n      <td>0.285058</td>\n      <td>0.179728</td>\n      <td>0.215778</td>\n      <td>0.224608</td>\n      <td>0.231965</td>\n      <td>0.237554</td>\n      <td>0.240082</td>\n      <td>538.0</td>\n      <td>0.179728</td>\n      <td>0.087774</td>\n      <td>0.060397</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DFIC</td>\n      <td>0.174504</td>\n      <td>0.223850</td>\n      <td>0.238152</td>\n      <td>0.257576</td>\n      <td>0.286947</td>\n      <td>0.174504</td>\n      <td>0.212295</td>\n      <td>0.220080</td>\n      <td>0.228004</td>\n      <td>0.235334</td>\n      <td>0.237360</td>\n      <td>556.0</td>\n      <td>0.174504</td>\n      <td>0.085684</td>\n      <td>0.058098</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LGD</td>\n      <td>0.179728</td>\n      <td>0.226189</td>\n      <td>0.239857</td>\n      <td>0.258974</td>\n      <td>0.288781</td>\n      <td>0.179728</td>\n      <td>0.215430</td>\n      <td>0.222745</td>\n      <td>0.230653</td>\n      <td>0.238008</td>\n      <td>0.240123</td>\n      <td>551.0</td>\n      <td>0.179728</td>\n      <td>0.085684</td>\n      <td>0.057889</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>In Exp  B2</td>\n      <td>0.187043</td>\n      <td>0.255546</td>\n      <td>0.269169</td>\n      <td>0.290187</td>\n      <td>0.312461</td>\n      <td>0.188088</td>\n      <td>0.238419</td>\n      <td>0.246151</td>\n      <td>0.255024</td>\n      <td>0.260360</td>\n      <td>0.262796</td>\n      <td>594.0</td>\n      <td>0.188088</td>\n      <td>0.100662</td>\n      <td>0.067294</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from pyterrier.measures import nDCG, RR, MAP\n\npt.Experiment(\n    trained_models,\n    prepared_trainqueries[:1000],\n    prepared_train_qrels[:1000],\n    names=names,\n    eval_metrics=eval_metrics,\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"7C9lfwR5KPsP","outputId":"d92b774f-fcd1-401d-8e45-b861dbe12d8a","execution":{"iopub.status.busy":"2024-03-30T12:45:55.669179Z","iopub.execute_input":"2024-03-30T12:45:55.669544Z","iopub.status.idle":"2024-03-30T12:57:20.207173Z","shell.execute_reply.started":"2024-03-30T12:45:55.669513Z","shell.execute_reply":"2024-03-30T12:57:20.205243Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"          name  nDCG@1    nDCG@3    nDCG@5   nDCG@10   nDCG@30   RR@1  \\\n0         BM25   0.193  0.248249  0.264344  0.282649  0.308248  0.193   \n1  LemurTF_IDF   0.178  0.225439  0.241790  0.259810  0.283194  0.178   \n2  Hiemstra LM   0.170  0.225249  0.243023  0.262364  0.282897  0.171   \n3         DFIC   0.173  0.227094  0.245211  0.262290  0.287101  0.173   \n4          LGD   0.175  0.228285  0.243175  0.261488  0.287122  0.175   \n5   In Exp  B2   0.204  0.256249  0.276344  0.294168  0.318248  0.205   \n\n       RR@3      RR@5     RR@10     RR@30        AP  NumRet(rel=1)  Judged@1  \\\n0  0.234667  0.243817  0.251682  0.257874  0.260094          611.0     0.193   \n1  0.213500  0.222950  0.230040  0.235929  0.238477          591.0     0.178   \n2  0.212000  0.221950  0.229875  0.234765  0.236672          571.0     0.171   \n3  0.214000  0.223750  0.230844  0.236745  0.239239          598.0     0.173   \n4  0.214500  0.222800  0.230433  0.236900  0.239096          589.0     0.175   \n5  0.244000  0.255350  0.262834  0.268601  0.270538          625.0     0.205   \n\n   Judged@3  Judged@5  \n0  0.095333    0.0652  \n1  0.086000    0.0600  \n2  0.088000    0.0614  \n3  0.089000    0.0620  \n4  0.089667    0.0610  \n5  0.097000    0.0682  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>nDCG@1</th>\n      <th>nDCG@3</th>\n      <th>nDCG@5</th>\n      <th>nDCG@10</th>\n      <th>nDCG@30</th>\n      <th>RR@1</th>\n      <th>RR@3</th>\n      <th>RR@5</th>\n      <th>RR@10</th>\n      <th>RR@30</th>\n      <th>AP</th>\n      <th>NumRet(rel=1)</th>\n      <th>Judged@1</th>\n      <th>Judged@3</th>\n      <th>Judged@5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BM25</td>\n      <td>0.193</td>\n      <td>0.248249</td>\n      <td>0.264344</td>\n      <td>0.282649</td>\n      <td>0.308248</td>\n      <td>0.193</td>\n      <td>0.234667</td>\n      <td>0.243817</td>\n      <td>0.251682</td>\n      <td>0.257874</td>\n      <td>0.260094</td>\n      <td>611.0</td>\n      <td>0.193</td>\n      <td>0.095333</td>\n      <td>0.0652</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LemurTF_IDF</td>\n      <td>0.178</td>\n      <td>0.225439</td>\n      <td>0.241790</td>\n      <td>0.259810</td>\n      <td>0.283194</td>\n      <td>0.178</td>\n      <td>0.213500</td>\n      <td>0.222950</td>\n      <td>0.230040</td>\n      <td>0.235929</td>\n      <td>0.238477</td>\n      <td>591.0</td>\n      <td>0.178</td>\n      <td>0.086000</td>\n      <td>0.0600</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hiemstra LM</td>\n      <td>0.170</td>\n      <td>0.225249</td>\n      <td>0.243023</td>\n      <td>0.262364</td>\n      <td>0.282897</td>\n      <td>0.171</td>\n      <td>0.212000</td>\n      <td>0.221950</td>\n      <td>0.229875</td>\n      <td>0.234765</td>\n      <td>0.236672</td>\n      <td>571.0</td>\n      <td>0.171</td>\n      <td>0.088000</td>\n      <td>0.0614</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DFIC</td>\n      <td>0.173</td>\n      <td>0.227094</td>\n      <td>0.245211</td>\n      <td>0.262290</td>\n      <td>0.287101</td>\n      <td>0.173</td>\n      <td>0.214000</td>\n      <td>0.223750</td>\n      <td>0.230844</td>\n      <td>0.236745</td>\n      <td>0.239239</td>\n      <td>598.0</td>\n      <td>0.173</td>\n      <td>0.089000</td>\n      <td>0.0620</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LGD</td>\n      <td>0.175</td>\n      <td>0.228285</td>\n      <td>0.243175</td>\n      <td>0.261488</td>\n      <td>0.287122</td>\n      <td>0.175</td>\n      <td>0.214500</td>\n      <td>0.222800</td>\n      <td>0.230433</td>\n      <td>0.236900</td>\n      <td>0.239096</td>\n      <td>589.0</td>\n      <td>0.175</td>\n      <td>0.089667</td>\n      <td>0.0610</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>In Exp  B2</td>\n      <td>0.204</td>\n      <td>0.256249</td>\n      <td>0.276344</td>\n      <td>0.294168</td>\n      <td>0.318248</td>\n      <td>0.205</td>\n      <td>0.244000</td>\n      <td>0.255350</td>\n      <td>0.262834</td>\n      <td>0.268601</td>\n      <td>0.270538</td>\n      <td>625.0</td>\n      <td>0.205</td>\n      <td>0.097000</td>\n      <td>0.0682</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}