{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:10.827712Z",
     "iopub.status.busy": "2024-03-29T22:14:10.827209Z",
     "iopub.status.idle": "2024-03-29T22:14:10.833452Z",
     "shell.execute_reply": "2024-03-29T22:14:10.832185Z",
     "shell.execute_reply.started": "2024-03-29T22:14:10.827677Z"
    },
    "id": "EdYzrLhxMTlW",
    "outputId": "34f98e14-b479-4070-90ac-139dc7a222b2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:10.842893Z",
     "iopub.status.busy": "2024-03-29T22:14:10.842457Z",
     "iopub.status.idle": "2024-03-29T22:14:23.581429Z",
     "shell.execute_reply": "2024-03-29T22:14:23.579906Z",
     "shell.execute_reply.started": "2024-03-29T22:14:10.842856Z"
    },
    "id": "3UmQotmJMUrs",
    "outputId": "b33cf819-d36d-4aad-a73a-d3ae37d66151",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pip install python-terrier==0.10.0 nltk scikit-learn lightgbm xgboost fastrank\n",
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:23.585214Z",
     "iopub.status.busy": "2024-03-29T22:14:23.584670Z",
     "iopub.status.idle": "2024-03-29T22:14:23.591456Z",
     "shell.execute_reply": "2024-03-29T22:14:23.590126Z",
     "shell.execute_reply.started": "2024-03-29T22:14:23.585167Z"
    },
    "id": "sRDXt2WiBNih",
    "outputId": "d2940d6f-f8c6-4c02-ff38-44a62f187340",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade git+https://github.com/Georgetown-IR-Lab/OpenNIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:23.593381Z",
     "iopub.status.busy": "2024-03-29T22:14:23.593026Z",
     "iopub.status.idle": "2024-03-29T22:14:23.603136Z",
     "shell.execute_reply": "2024-03-29T22:14:23.602202Z",
     "shell.execute_reply.started": "2024-03-29T22:14:23.593352Z"
    },
    "id": "EYhewvEjL-7Y",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chrys\\Documents\\CSE\\MASTERS\\Q3\\Information Retrieval\\moment_retrieval\\moment_retrieval\\ir-python-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pyterrier as pt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:23.606925Z",
     "iopub.status.busy": "2024-03-29T22:14:23.606397Z",
     "iopub.status.idle": "2024-03-29T22:14:23.615843Z",
     "shell.execute_reply": "2024-03-29T22:14:23.614568Z",
     "shell.execute_reply.started": "2024-03-29T22:14:23.606878Z"
    },
    "id": "nKsBbMKjEepz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#UNCOMMENT THE FOLLOWING LINE TO USE EITHER THE TVR DATASET OR THE QVH DATASET\n",
    "\n",
    "dataset_choice = \"TVR\"\n",
    "# dataset_choice = \"QVH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:23.618181Z",
     "iopub.status.busy": "2024-03-29T22:14:23.617786Z",
     "iopub.status.idle": "2024-03-29T22:14:23.628769Z",
     "shell.execute_reply": "2024-03-29T22:14:23.627711Z",
     "shell.execute_reply.started": "2024-03-29T22:14:23.618149Z"
    },
    "id": "UruQwRMsOrNj",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths to JSONL files on Colab\n",
    "# if dataset_choice == \"TVR\":\n",
    "#    jsonl_train_path = '/content/drive/MyDrive/IR/text_data/tvr_train_release.jsonl'\n",
    "#    jsonl_val_path = '/content/drive/MyDrive/IR/text_data/tvr_val_release.jsonl'\n",
    "#    subs_path = '/content/drive/MyDrive/IR/text_data/tvqa_preprocessed_subtitles.jsonl'\n",
    "\n",
    "# elif dataset_choice == \"QVH\":\n",
    "#    jsonl_train_path = \"/content/drive/MyDrive/IR/text_data_QVH/highlight_train_release.jsonl\"\n",
    "#    subs_path = \"/content/drive/MyDrive/IR/text_data_QVH/subs_train.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:23.631290Z",
     "iopub.status.busy": "2024-03-29T22:14:23.630522Z",
     "iopub.status.idle": "2024-03-29T22:14:23.642651Z",
     "shell.execute_reply": "2024-03-29T22:14:23.641593Z",
     "shell.execute_reply.started": "2024-03-29T22:14:23.631255Z"
    },
    "id": "W17JgCyFL-7Z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths to JSONL files\n",
    "if dataset_choice == \"TVR\":\n",
    "    # jsonl_train_path = '/kaggle/input/tvretrieval/tvr_train_release.jsonl'\n",
    "    # jsonl_val_path = '/kaggle/input/tvretrieval/tvr_val_release.jsonl'\n",
    "    # subs_path = '/kaggle/input/tvretrieval/tvqa_preprocessed_subtitles.jsonl'\n",
    "    jsonl_train_path = 'text_data/tvr_train_release.jsonl'\n",
    "    jsonl_val_path = 'text_data/tvr_val_release.jsonl'\n",
    "    subs_path = 'text_data/tvqa_preprocessed_subtitles.jsonl'\n",
    "\n",
    "elif dataset_choice == \"QVH\":\n",
    "    jsonl_train_path = \"text_data_QVH/highlight_train_release.jsonl\"\n",
    "    subs_path = \"text_data_QVH/subs_train.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:23.644660Z",
     "iopub.status.busy": "2024-03-29T22:14:23.644287Z",
     "iopub.status.idle": "2024-03-29T22:14:24.564856Z",
     "shell.execute_reply": "2024-03-29T22:14:24.563619Z",
     "shell.execute_reply.started": "2024-03-29T22:14:23.644632Z"
    },
    "id": "L6VZMDuDL-7Z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load subtitles into a dictionary for quick access\n",
    "subtitles_dict = {}\n",
    "if dataset_choice == \"TVR\":\n",
    "    with open(subs_path, 'r') as subs_file:\n",
    "        for line in subs_file:\n",
    "            sub_data = json.loads(line)\n",
    "            subtitles_dict[sub_data['vid_name']] = sub_data['sub']\n",
    "elif dataset_choice == \"QVH\":\n",
    "    with open(subs_path, 'r') as subs_file:\n",
    "        for line in subs_file:\n",
    "            sub_data = json.loads(line)\n",
    "            triple = sub_data['vid'].split(\"_\")\n",
    "            name = sub_data['vid']\n",
    "            #turn the list name into a string\n",
    "            name = \"\".join(name)\n",
    "            if name not in subtitles_dict:\n",
    "                subtitles_dict[name] = [(float(triple[-2]) + sub_data[\"relevant_windows\"][0][0], float(triple[-2]) + sub_data[\"relevant_windows\"][0][1], sub_data['query'])]\n",
    "            else:\n",
    "                subtitles_dict[name].append((float(triple[-2]) + sub_data[\"relevant_windows\"][0][0], float(triple[-2]) + sub_data[\"relevant_windows\"][0][1], sub_data['query']))\n",
    "            \n",
    "            # print(subtitles_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:24.567536Z",
     "iopub.status.busy": "2024-03-29T22:14:24.567036Z",
     "iopub.status.idle": "2024-03-29T22:14:24.574407Z",
     "shell.execute_reply": "2024-03-29T22:14:24.573302Z",
     "shell.execute_reply.started": "2024-03-29T22:14:24.567489Z"
    },
    "id": "UkWQOjjYL-7Z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to find matching subtitles in TVR case\n",
    "def find_matching_subtitles(vid_name, ts_range, subtitles_dict):\n",
    "    matching_subs = []\n",
    "    if vid_name in subtitles_dict:\n",
    "        for subtitle in subtitles_dict[vid_name]:\n",
    "            if (ts_range[0] <= subtitle['start'] <= ts_range[1]) or (ts_range[0] <= subtitle['end'] <= ts_range[1]) or (subtitle['start'] <= ts_range[0] and subtitle['end'] >= ts_range[1]):\n",
    "                matching_subs.append(subtitle['text'])\n",
    "    return matching_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:24.577308Z",
     "iopub.status.busy": "2024-03-29T22:14:24.576383Z",
     "iopub.status.idle": "2024-03-29T22:14:24.599642Z",
     "shell.execute_reply": "2024-03-29T22:14:24.598571Z",
     "shell.execute_reply.started": "2024-03-29T22:14:24.577274Z"
    },
    "id": "HDx8ntjxL-7a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def parse_jsonl_TVR(jsonl_path, split_type):\n",
    "    # Initialize empty lists for your data\n",
    "    queries_data = []\n",
    "    documents_data = []\n",
    "    query_rankings_data = []\n",
    "\n",
    "    with open(jsonl_path, 'r') as file:\n",
    "        for idx, line in enumerate(file):\n",
    "            data = json.loads(line)\n",
    "            # drop non text-based queries\n",
    "            if data['type'] not in ['t']:   # t: text-based, vt: video-text-based -> You can choose here\n",
    "                continue\n",
    "\n",
    "            # Find matching subtitles\n",
    "            matching_subs = find_matching_subtitles(data['vid_name'], data['ts'], subtitles_dict)\n",
    "\n",
    "            if matching_subs == []:\n",
    "                continue\n",
    "\n",
    "            # Extract data for the Query Set DataFrame\n",
    "            queries_data.append({'qid': str(data['desc_id']), 'query': data['desc']})\n",
    "\n",
    "            # Extract data for the Documents Set DataFrame, including matching subtitles\n",
    "            documents_data.append({'docno': split_type + str(idx), 'vid_name': data['vid_name'], 'ts': data['ts'],\n",
    "                                'duration': data['duration'], 'type': data['type'], 'text': \"\".join(matching_subs)})\n",
    "\n",
    "            # Extract data for the Query Rankings DataFrame\n",
    "            query_rankings_data.append({'qid': str(data[\"desc_id\"]), 'query': data['desc'], 'docno': split_type + str(idx), 'rank': 1, 'score': 1.0})\n",
    "\n",
    "    return queries_data, documents_data, query_rankings_data\n",
    "\n",
    "def parse_jsonl_QVH(jsonl_path):\n",
    "    queries_data = []\n",
    "    documents_data = []\n",
    "    query_rankings_data = []\n",
    "    with open(jsonl_path, 'r') as file:\n",
    "        for idx,line in enumerate(file):\n",
    "\n",
    "            # Load the JSON object from the line\n",
    "            data = json.loads(line)\n",
    "\n",
    "            triple = data[\"vid\"].split(\"_\")\n",
    "            document_name = triple[0:-2]\n",
    "            document_name = data[\"vid\"]\n",
    "            start_time = float(triple[-2])\n",
    "            end_time = float(triple[-1])\n",
    "\n",
    "            if document_name not in subtitles_dict:\n",
    "                #print(\"Document not found in subtitles: \", document_name)\n",
    "                continue\n",
    "            \n",
    "            subs = []\n",
    "            for relevant_window in data[\"relevant_windows\"]:\n",
    "                ts = [start_time+relevant_window[0], start_time+relevant_window[1]]\n",
    "                subs.extend([sub for sub in subtitles_dict[document_name] if sub[0] <= ts[1] and ts[0] <= sub[1]])\n",
    "                if len(subs) == 0:\n",
    "                    #print(\"No subtitles found for \", document_name, \" at time \", ts)\n",
    "                    continue\n",
    "            \n",
    "            documents_data.append({\"docno\": str(idx), \"vid_name\": document_name, \"ts\": [start_time, end_time], \"duration\" : data[\"duration\"], \"text\": \" \".join([sub[2] for sub in subs])})\n",
    "            queries_data.append({\"qid\" : str(data[\"qid\"]), \"query\": data[\"query\"]})\n",
    "            query_rankings_data.append({\"qid\": str(data[\"qid\"]), \"query\": data[\"query\"], \"docno\": str(idx), \"rank\": 1, \"score\": 1.0})\n",
    "\n",
    "    return queries_data, documents_data, query_rankings_data\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:24.605156Z",
     "iopub.status.busy": "2024-03-29T22:14:24.604756Z",
     "iopub.status.idle": "2024-03-29T22:14:27.963265Z",
     "shell.execute_reply": "2024-03-29T22:14:27.962030Z",
     "shell.execute_reply.started": "2024-03-29T22:14:24.605125Z"
    },
    "id": "Ae33k1XsEep2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if dataset_choice == \"TVR\":\n",
    "    queries_data_train, documents_data_train, query_rankings_data_train = parse_jsonl_TVR(jsonl_train_path, \"t\")\n",
    "    queries_data_val, documents_data_val, query_rankings_data_val = parse_jsonl_TVR(jsonl_val_path, \"v\")\n",
    "    #have to create a test set; to do it, extract a random 10% of the train set\n",
    "    random.seed(42)\n",
    "    query_rankings_data_test = random.sample(query_rankings_data_train, int(len(query_rankings_data_train)*0.1))\n",
    "    query_rankings_data_train = [query for query in query_rankings_data_train if query not in query_rankings_data_test]\n",
    "    queries_data_test = [query for query in queries_data_train if query[\"qid\"] in [query[\"qid\"] for query in query_rankings_data_test]]\n",
    "    queries_data_train = [query for query in queries_data_train if query not in queries_data_test]\n",
    "    documents_data_test = [doc for doc in documents_data_train if doc[\"docno\"] in [query[\"docno\"] for query in query_rankings_data_test]]\n",
    "    documents_data_train = [doc for doc in documents_data_train if doc not in documents_data_test]\n",
    "\n",
    "elif dataset_choice == \"QVH\":\n",
    "    queries_data_train, documents_data_train, query_rankings_data_train = parse_jsonl_QVH(jsonl_train_path)\n",
    "    #have to create a val set; to do it, extract a random 10% of the train set\n",
    "    random.seed(42)\n",
    "    query_rankings_data_val = random.sample(query_rankings_data_train, int(len(query_rankings_data_train)*0.1))\n",
    "    query_rankings_data_train = [query for query in query_rankings_data_train if query not in query_rankings_data_val]\n",
    "    queries_data_val = [query for query in queries_data_train if query[\"qid\"] in [query[\"qid\"] for query in query_rankings_data_val]]\n",
    "    queries_data_train = [query for query in queries_data_train if query not in queries_data_val]\n",
    "    documents_data_val = [doc for doc in documents_data_train if doc[\"docno\"] in [query[\"docno\"] for query in query_rankings_data_val]]\n",
    "    documents_data_train = [doc for doc in documents_data_train if doc not in documents_data_val]\n",
    "    #have to create a test set; to do it, extract a random 10% of the train set\n",
    "    random.seed(42)\n",
    "    query_rankings_data_test = random.sample(query_rankings_data_train, int(len(query_rankings_data_train)*0.1))\n",
    "    query_rankings_data_train = [query for query in query_rankings_data_train if query not in query_rankings_data_test]\n",
    "    queries_data_test = [query for query in queries_data_train if query[\"qid\"] in [query[\"qid\"] for query in query_rankings_data_test]]\n",
    "    queries_data_train = [query for query in queries_data_train if query not in queries_data_test]\n",
    "    documents_data_test = [doc for doc in documents_data_train if doc[\"docno\"] in [query[\"docno\"] for query in query_rankings_data_test]]\n",
    "    documents_data_train = [doc for doc in documents_data_train if doc not in documents_data_test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:27.965248Z",
     "iopub.status.busy": "2024-03-29T22:14:27.964774Z",
     "iopub.status.idle": "2024-03-29T22:14:28.031936Z",
     "shell.execute_reply": "2024-03-29T22:14:28.030835Z",
     "shell.execute_reply.started": "2024-03-29T22:14:27.965205Z"
    },
    "id": "ZTiDgmaqL-7a",
    "outputId": "b7e64317-7faf-47c4-e8a9-20be5a030ea7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "Queries:  7110\n",
      "Documents:  7110\n",
      "Val set:\n",
      "Queries:  957\n",
      "Documents:  957\n",
      "Test set:\n",
      "Queries:  790\n",
      "Documents:  790\n",
      "Query Rankings:  8857\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrames for the Query Set, Documents Set, and Query Rankings\n",
    "queries_train_df = pd.DataFrame(queries_data_train)\n",
    "documents_train_df = pd.DataFrame(documents_data_train)\n",
    "\n",
    "queries_val_df = pd.DataFrame(queries_data_val)\n",
    "documents_val_df = pd.DataFrame(documents_data_val)\n",
    "\n",
    "queries_test_df = pd.DataFrame(queries_data_test)\n",
    "documents_test_df = pd.DataFrame(documents_data_test)\n",
    "\n",
    "q_rels = pd.concat([pd.DataFrame(query_rankings_data_train), pd.DataFrame(query_rankings_data_val), pd.DataFrame(query_rankings_data_test)]).reset_index(drop=True)\n",
    "\n",
    "#print length of the dataframes\n",
    "print(\"Train set:\")\n",
    "print(\"Queries: \", len(queries_train_df))\n",
    "print(\"Documents: \", len(documents_train_df))\n",
    "\n",
    "print(\"Val set:\")\n",
    "print(\"Queries: \", len(queries_val_df))\n",
    "print(\"Documents: \", len(documents_val_df))\n",
    "\n",
    "print(\"Test set:\")\n",
    "print(\"Queries: \", len(queries_test_df))\n",
    "print(\"Documents: \", len(documents_test_df))\n",
    "\n",
    "print(\"Query Rankings: \", len(q_rels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCaV5vcXL-7a"
   },
   "source": [
    "### First Stage Retrieval [TODO: BOX]\n",
    "The following part of the code will define three different first stage retrieval pipelines as an input for the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:28.033785Z",
     "iopub.status.busy": "2024-03-29T22:14:28.033350Z",
     "iopub.status.idle": "2024-03-29T22:14:29.077658Z",
     "shell.execute_reply": "2024-03-29T22:14:29.076333Z",
     "shell.execute_reply.started": "2024-03-29T22:14:28.033747Z"
    },
    "id": "5-SsgPJwVMXw",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:29.080004Z",
     "iopub.status.busy": "2024-03-29T22:14:29.079579Z",
     "iopub.status.idle": "2024-03-29T22:14:29.087921Z",
     "shell.execute_reply": "2024-03-29T22:14:29.086652Z",
     "shell.execute_reply.started": "2024-03-29T22:14:29.079969Z"
    },
    "id": "Xx55BjIGfNNa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create an index\n",
    "\n",
    "index_path = r\"c:\\Users\\chrys\\Documents\\CSE\\MASTERS\\Q3\\Information Retrieval\\moment_retrieval\\moment_retrieval\\index_path\"\n",
    "\n",
    "indexer = pt.IterDictIndexer(\n",
    "    index_path,\n",
    "    meta={\n",
    "        \"docno\": 64,\n",
    "        \"vid_name\": 64,\n",
    "        \"text\": 131072,\n",
    "    },\n",
    "    stemmer=\"porter\",\n",
    "    stopwords=\"terrier\",\n",
    "    overwrite=True,\n",
    "    type=pt.index.IndexingType.MEMORY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:29.090038Z",
     "iopub.status.busy": "2024-03-29T22:14:29.089700Z",
     "iopub.status.idle": "2024-03-29T22:14:29.125988Z",
     "shell.execute_reply": "2024-03-29T22:14:29.124474Z",
     "shell.execute_reply.started": "2024-03-29T22:14:29.090009Z"
    },
    "id": "T1W-_BFDjpqS",
    "outputId": "657431e1-1296-4391-9ac1-113827b51bcd",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:  8857\n"
     ]
    }
   ],
   "source": [
    "joint_documents_set_df = pd.concat([documents_train_df, documents_val_df, documents_test_df])\n",
    "\n",
    "print(\"Length: \", len(joint_documents_set_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:29.128500Z",
     "iopub.status.busy": "2024-03-29T22:14:29.127642Z",
     "iopub.status.idle": "2024-03-29T22:14:34.388679Z",
     "shell.execute_reply": "2024-03-29T22:14:34.387370Z",
     "shell.execute_reply.started": "2024-03-29T22:14:29.128457Z"
    },
    "id": "R_PnpogfjpqS",
    "outputId": "6909ba8e-62af-4f78-da7d-59ce66637ba4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "indexed = indexer.index(\n",
    "    joint_documents_set_df.to_dict(orient=\"records\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.measures import *\n",
    "\n",
    "n_r = 50  # Number of documents retrieved in the first stage\n",
    "\n",
    "first_stage_bm25 = pt.BatchRetrieve(\n",
    "    indexed,\n",
    "    wmodel=\"BM25\",\n",
    "    num_results=n_r,\n",
    "    metadata=[\"docno\", \"vid_name\", \"text\"]\n",
    ")\n",
    "\n",
    "# Initialize BatchRetrieve with the created index and specify LemurTF_IDF as the weighting model\n",
    "first_stage_lemurtfidf = pt.BatchRetrieve(\n",
    "    indexed,\n",
    "    wmodel=\"LemurTF_IDF\",\n",
    "    num_results=n_r,\n",
    "    metadata=[\"docno\", \"vid_name\", \"text\"]\n",
    ")\n",
    "\n",
    "first_stage_pl2 = pt.BatchRetrieve(\n",
    "    indexed,\n",
    "    wmodel=\"PL2\",\n",
    "    num_results=n_r,\n",
    "    metadata=[\"docno\", \"vid_name\", \"text\"]\n",
    ")\n",
    "\n",
    "first_stage_in_exp_b2 = pt.BatchRetrieve(\n",
    "    indexed,\n",
    "    wmodel=\"In_expB2\",\n",
    "    num_results=n_r,\n",
    "    metadata=[\"docno\", \"vid_name\", \"text\"]\n",
    ")\n",
    "\n",
    "### \n",
    "first_stage_retrieval_list = [first_stage_bm25, first_stage_pl2, first_stage_in_exp_b2] if dataset_choice == \"TVR\" else [first_stage_bm25, first_stage_lemurtfidf, first_stage_in_exp_b2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vCeCMoUvedO"
   },
   "source": [
    "# Computing feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:34.417286Z",
     "iopub.status.busy": "2024-03-29T22:14:34.416459Z",
     "iopub.status.idle": "2024-03-29T22:14:34.453743Z",
     "shell.execute_reply": "2024-03-29T22:14:34.452673Z",
     "shell.execute_reply.started": "2024-03-29T22:14:34.417244Z"
    },
    "id": "QTBZtHYLy_fH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#We create features for the second stage using the first stage retrievers\n",
    "\n",
    "#TF-IDF based features\n",
    "lemur_tf_idf_retriever = pt.BatchRetrieve(indexed, wmodel=\"LemurTF_IDF\")  # LemurTF_IDF -> It is a TF-IDF based weighting model\n",
    "bm25_retriever = pt.BatchRetrieve(indexed, wmodel=\"BM25\")\n",
    "\n",
    "#Language model based features\n",
    "hiem_retriever = pt.BatchRetrieve(indexed, wmodel=\"Hiemstra_LM\")\n",
    "dirichlet_retriever = pt.BatchRetrieve(indexed, wmodel=\"DirichletLM\")\n",
    "\n",
    "#Divergence from randomness based features\n",
    "pl2_retriever = pt.BatchRetrieve(indexed, wmodel=\"PL2\")\n",
    "dlh_retriever = pt.BatchRetrieve(indexed, wmodel=\"DLH\")\n",
    "\n",
    "#Can add more!\n",
    "coordinate_match_retriever = pt.BatchRetrieve(indexed, wmodel=\"CoordinateMatch\")\n",
    "js_kls_retrieveer = pt.BatchRetrieve(indexed, wmodel=\"Js_KLs\")\n",
    "\n",
    "bm25_QE_retriever = pt.BatchRetrieve(indexed, wmodel=\"BM25\", controls={\"qe\": \"on\", \"qemodel\": \"bo1\"})\n",
    "hiem_QE_retriever = pt.BatchRetrieve(indexed, wmodel=\"Hiemstra_LM\", controls={\"qe\": \"on\", \"qemodel\": \"bo1\"})\n",
    "pl2_QE_retriever = pt.BatchRetrieve(indexed, wmodel=\"PL2\", controls={\"qe\": \"on\", \"qemodel\": \"bo1\"})\n",
    "coordinate_match_QE_retriever = pt.BatchRetrieve(indexed, wmodel=\"CoordinateMatch\", controls={\"qe\": \"on\", \"qemodel\": \"bo1\"})\n",
    "# 1. PL2 + DLH\n",
    "# 2. BM25 + Hiemstra_LM + PL2 + CoordinateMatch\n",
    "# 3. BM25 (QE) + HiemstraLM (QE) + PL2 (QE) + CoordinateMatch (QE)\n",
    "# 4. LemurTF_IDF + DirichletLM + DLH + Js_KLs\n",
    "feature_combinations = [ \n",
    "    (pl2_retriever ** dlh_retriever), \n",
    "    (bm25_retriever ** hiem_retriever ** pl2_retriever ** coordinate_match_retriever), \n",
    "    (bm25_QE_retriever ** hiem_QE_retriever ** pl2_QE_retriever ** coordinate_match_QE_retriever), \n",
    "    (lemur_tf_idf_retriever ** dirichlet_retriever ** dlh_retriever ** js_kls_retrieveer)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:14:34.481665Z",
     "iopub.status.busy": "2024-03-29T22:14:34.480711Z",
     "iopub.status.idle": "2024-03-29T22:14:34.766290Z",
     "shell.execute_reply": "2024-03-29T22:14:34.765059Z",
     "shell.execute_reply.started": "2024-03-29T22:14:34.481621Z"
    },
    "id": "QE1WrfC8zJjm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare the queries for the pipeline, remove special characters and extra spaces\n",
    "prepared_trainqueries = queries_train_df\n",
    "prepared_trainqueries['query'] = prepared_trainqueries['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
    "prepared_trainqueries['query'] = prepared_trainqueries['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "prepared_trainqueries['query'] = prepared_trainqueries['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "prepared_train_qrels = pd.DataFrame(query_rankings_data_train)\n",
    "prepared_train_qrels['query'] = prepared_train_qrels['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
    "prepared_train_qrels['query'] = prepared_train_qrels['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "prepared_train_qrels['query'] = prepared_train_qrels['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "prepared_train_qrels['label'] = prepared_train_qrels['score']\n",
    "\n",
    "prepared_train_qrels['label'] = prepared_train_qrels['label'].astype(int)\n",
    "\n",
    "prepared_val_qrels = pd.DataFrame(query_rankings_data_val)\n",
    "prepared_val_qrels['query'] = prepared_val_qrels['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
    "prepared_val_qrels['query'] = prepared_val_qrels['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "prepared_val_qrels['query'] = prepared_val_qrels['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "prepared_val_qrels['label'] = prepared_val_qrels['score']\n",
    "\n",
    "prepared_val_qrels['label'] = prepared_val_qrels['label'].astype(int)\n",
    "\n",
    "prepared_test_qrels = pd.DataFrame(query_rankings_data_test)\n",
    "prepared_test_qrels['query'] = prepared_test_qrels['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
    "prepared_test_qrels['query'] = prepared_test_qrels['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "prepared_test_qrels['query'] = prepared_test_qrels['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "prepared_test_qrels['label'] = prepared_test_qrels['score']\n",
    "\n",
    "prepared_test_qrels['label'] = prepared_test_qrels['label'].astype(int)\n",
    "\n",
    "prepared_qrels = q_rels\n",
    "prepared_qrels['query'] = prepared_qrels['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
    "prepared_qrels['query'] = prepared_qrels['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "prepared_qrels['query'] = prepared_qrels['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "prepared_qrels['label'] = prepared_qrels['score']\n",
    "\n",
    "prepared_qrels['label'] = prepared_qrels['label'].astype(int)\n",
    "\n",
    "prepared_valqueries = queries_val_df.reset_index()\n",
    "prepared_valqueries['query'] = prepared_valqueries['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
    "prepared_valqueries['query'] = prepared_valqueries['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "\n",
    "prepared_valqueries['query'] = prepared_valqueries['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "#test set\n",
    "prepared_testqueries = queries_test_df.reset_index()\n",
    "prepared_testqueries['query'] = prepared_testqueries['query'].str.replace('[\\'\"?!]', ' ', regex=True)\n",
    "prepared_testqueries['query'] = prepared_testqueries['query'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "prepared_testqueries['query'] = prepared_testqueries['query'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLeXGDj8rGcx"
   },
   "source": [
    "Storage format: .csv or trec\n",
    "\n",
    "trec(https://pyterrier.readthedocs.io/en/latest/io.html): The pt io format, but it doesn't contain feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T22:28:25.553433Z",
     "iopub.status.busy": "2024-03-29T22:28:25.552115Z",
     "iopub.status.idle": "2024-03-29T22:28:25.562847Z",
     "shell.execute_reply": "2024-03-29T22:28:25.561863Z",
     "shell.execute_reply.started": "2024-03-29T22:28:25.553367Z"
    },
    "id": "RGv0tMvLEep6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "import xgboost as xgb\n",
    "import fastrank\n",
    "from pyterrier.measures import *\n",
    "\n",
    "index = pt.IndexFactory.of(r\"c:\\Users\\chrys\\Documents\\CSE\\MASTERS\\Q3\\Information Retrieval\\moment_retrieval\\moment_retrieval\\index_path\")\n",
    "\n",
    "learned_models = [\n",
    "    {\n",
    "        'model': LinearSVR(),\n",
    "        'form': 'reg',\n",
    "        'name': 'linearSVR',\n",
    "    },\n",
    "    {\n",
    "       'model': xgb.XGBRanker(tree_method=\"hist\", objective=\"rank:ndcg\", device= \"cuda\"),\n",
    "       'form': 'ltr',\n",
    "       'name': 'XGBoost (NDCG)',\n",
    "    },\n",
    "    {\n",
    "       'model': fastrank.TrainRequest.coordinate_ascent(),\n",
    "       'form': 'fastrank',\n",
    "       'name': 'FastRank Coordinate Ascent',\n",
    "    },\n",
    "    {\n",
    "       'model': fastrank.TrainRequest.random_forest(),\n",
    "       'form': 'fastrank',\n",
    "       'name': 'FastRank Random Forest',\n",
    "    }\n",
    "  ]\n",
    "\n",
    "eval_metrics = [\n",
    "    MAP, MRR,\n",
    "    nDCG @ 1, nDCG @ 3, nDCG @ 5, nDCG @ 10,\n",
    "    nDCG @ 20, nDCG @ 30, nDCG @ 50,\n",
    "    Recall @ 1, Recall @ 3, Recall @ 5, Recall @ 10,\n",
    "    Recall @ 20, Recall @ 30, Recall @ 50,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T22:28:26.413060Z",
     "iopub.status.busy": "2024-03-29T22:28:26.412653Z",
     "iopub.status.idle": "2024-03-29T22:33:09.324373Z",
     "shell.execute_reply": "2024-03-29T22:33:09.323179Z",
     "shell.execute_reply.started": "2024-03-29T22:28:26.413029Z"
    },
    "id": "lOrma3FeEep6",
    "outputId": "c89521e4-6c24-4e33-e240-33abc9817088",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of configuration:  BM25_0_linearSVR\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Try all possible combinations of \n",
    "- First stage retrieval models (first_stage_retrieval_list)\n",
    "- Feature combinations  (feature_combinations)\n",
    "- Learned models  (learned_models)\n",
    "'''\n",
    "\n",
    "for fsr_alg in first_stage_retrieval_list[0:2]:\n",
    "    for i, feature_comb in enumerate(feature_combinations):\n",
    "        for model in learned_models[0:2]:\n",
    "            # combine the features with ** operator\n",
    "            fsr = ~fsr_alg >> (feature_comb) \n",
    "            name = fsr_alg.controls[\"wmodel\"] + f\"_{i}_\" + f\"{model['name']}\"\n",
    "            print(\"Name of configuration: \", name)\n",
    "\n",
    "            pipeline = fsr >> pt.ltr.apply_learned_model(model['model'], form=model['form'])\n",
    "            pipeline.fit(\n",
    "                prepared_trainqueries,\n",
    "                prepared_train_qrels,  \n",
    "                prepared_valqueries,\n",
    "                prepared_val_qrels\n",
    "            )\n",
    "\n",
    "            print(\"Training done\")\n",
    "\n",
    "            pt.Experiment(\n",
    "                [pipeline],\n",
    "                prepared_testqueries,\n",
    "                prepared_test_qrels,\n",
    "                names=[name],\n",
    "                eval_metrics=eval_metrics,\n",
    "            ).to_csv(f\"experiments/test/{name}.csv\")\n",
    "\n",
    "            pt.Experiment(\n",
    "                [pipeline],\n",
    "                prepared_trainqueries.sample(frac=0.1, random_state=42),  # select the 10% of the train set\n",
    "                prepared_train_qrels,   \n",
    "                names=[name],\n",
    "                eval_metrics=eval_metrics,\n",
    "            ).to_csv(f\"experiments/train/{name}.csv\")\n",
    "\n",
    "            print(\"Experiments done:\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4694824,
     "sourceId": 7977303,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
